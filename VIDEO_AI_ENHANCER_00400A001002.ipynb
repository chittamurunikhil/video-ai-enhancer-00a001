{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wfvh5T81G77Z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting tensorflow\n",
            "  Using cached tensorflow-2.16.2-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
            "Collecting tensorflow-intel==2.16.2 (from tensorflow)\n",
            "  Using cached tensorflow_intel-2.16.2-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (4.25.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (69.5.1)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.62.2)\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.16.2)\n",
            "Requirement already satisfied: keras>=3.0.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.2->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (0.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (2.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (0.1.2)\n",
            "Using cached tensorflow-2.16.2-cp312-cp312-win_amd64.whl (2.1 kB)\n",
            "Using cached tensorflow_intel-2.16.2-cp312-cp312-win_amd64.whl (377.1 MB)\n",
            "Installing collected packages: tensorflow-intel, tensorflow\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python312\\\\site-packages\\\\tensorflow\\\\include\\\\external\\\\com_github_grpc_grpc\\\\src\\\\core\\\\ext\\\\filters\\\\client_channel\\\\lb_policy\\\\grpclb\\\\client_load_reporting_filter.h'\n",
            "HINT: This error might have occurred since this system does not have Windows Long Path support enabled. You can find information on how to enable this at https://pip.pypa.io/warnings/enable-long-paths\n",
            "\n",
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
            "[notice] To update, run: C:\\Users\\ADMIN\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.42.3-py3-none-any.whl.metadata (43 kB)\n",
            "     ---------------------------------------- 0.0/43.6 kB ? eta -:--:--\n",
            "     --------- ------------------------------ 10.2/43.6 kB ? eta -:--:--\n",
            "     -------------------------- ----------- 30.7/43.6 kB 330.3 kB/s eta 0:00:01\n",
            "     ----------------------------------- -- 41.0/43.6 kB 326.8 kB/s eta 0:00:01\n",
            "     -------------------------------------- 43.6/43.6 kB 267.1 kB/s eta 0:00:00\n",
            "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (3.13.4)\n",
            "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
            "  Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (6.0.1)\n",
            "Collecting regex!=2019.12.17 (from transformers)\n",
            "  Downloading regex-2024.5.15-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
            "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
            "     --------- ------------------------------ 10.2/42.0 kB ? eta -:--:--\n",
            "     --------- ------------------------------ 10.2/42.0 kB ? eta -:--:--\n",
            "     --------- ------------------------------ 10.2/42.0 kB ? eta -:--:--\n",
            "     --------- ------------------------------ 10.2/42.0 kB ? eta -:--:--\n",
            "     -------------------------------------  41.0/42.0 kB 140.9 kB/s eta 0:00:01\n",
            "     -------------------------------------- 42.0/42.0 kB 135.6 kB/s eta 0:00:00\n",
            "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (2.31.0)\n",
            "Collecting safetensors>=0.4.1 (from transformers)\n",
            "  Downloading safetensors-0.4.3-cp312-none-win_amd64.whl.metadata (3.9 kB)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
            "  Downloading tokenizers-0.19.1-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (2024.2.2)\n",
            "Downloading transformers-4.42.3-py3-none-any.whl (9.3 MB)\n",
            "   ---------------------------------------- 0.0/9.3 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.1/9.3 MB 1.7 MB/s eta 0:00:06\n",
            "   ---------------------------------------- 0.1/9.3 MB 1.3 MB/s eta 0:00:08\n",
            "    --------------------------------------- 0.1/9.3 MB 1.2 MB/s eta 0:00:08\n",
            "    --------------------------------------- 0.1/9.3 MB 1.2 MB/s eta 0:00:08\n",
            "    --------------------------------------- 0.1/9.3 MB 655.8 kB/s eta 0:00:15\n",
            "   - -------------------------------------- 0.2/9.3 MB 958.6 kB/s eta 0:00:10\n",
            "   - -------------------------------------- 0.3/9.3 MB 923.9 kB/s eta 0:00:10\n",
            "   - -------------------------------------- 0.3/9.3 MB 923.9 kB/s eta 0:00:10\n",
            "   - -------------------------------------- 0.3/9.3 MB 923.9 kB/s eta 0:00:10\n",
            "   - -------------------------------------- 0.3/9.3 MB 655.8 kB/s eta 0:00:14\n",
            "   - -------------------------------------- 0.3/9.3 MB 698.7 kB/s eta 0:00:13\n",
            "   - -------------------------------------- 0.4/9.3 MB 694.6 kB/s eta 0:00:13\n",
            "   - -------------------------------------- 0.4/9.3 MB 694.6 kB/s eta 0:00:13\n",
            "   - -------------------------------------- 0.4/9.3 MB 694.6 kB/s eta 0:00:13\n",
            "   - -------------------------------------- 0.4/9.3 MB 640.0 kB/s eta 0:00:14\n",
            "   - -------------------------------------- 0.5/9.3 MB 640.0 kB/s eta 0:00:14\n",
            "   - -------------------------------------- 0.5/9.3 MB 613.0 kB/s eta 0:00:15\n",
            "   - -------------------------------------- 0.5/9.3 MB 613.0 kB/s eta 0:00:15\n",
            "   -- ------------------------------------- 0.5/9.3 MB 581.3 kB/s eta 0:00:16\n",
            "   -- ------------------------------------- 0.5/9.3 MB 573.4 kB/s eta 0:00:16\n",
            "   -- ------------------------------------- 0.5/9.3 MB 573.4 kB/s eta 0:00:16\n",
            "   -- ------------------------------------- 0.5/9.3 MB 573.4 kB/s eta 0:00:16\n",
            "   -- ------------------------------------- 0.6/9.3 MB 554.3 kB/s eta 0:00:16\n",
            "   -- ------------------------------------- 0.6/9.3 MB 568.4 kB/s eta 0:00:16\n",
            "   -- ------------------------------------- 0.6/9.3 MB 569.9 kB/s eta 0:00:16\n",
            "   -- ------------------------------------- 0.6/9.3 MB 569.9 kB/s eta 0:00:16\n",
            "   -- ------------------------------------- 0.7/9.3 MB 536.3 kB/s eta 0:00:17\n",
            "   --- ------------------------------------ 0.7/9.3 MB 572.1 kB/s eta 0:00:16\n",
            "   --- ------------------------------------ 0.7/9.3 MB 567.6 kB/s eta 0:00:16\n",
            "   --- ------------------------------------ 0.7/9.3 MB 555.2 kB/s eta 0:00:16\n",
            "   --- ------------------------------------ 0.7/9.3 MB 555.2 kB/s eta 0:00:16\n",
            "   --- ------------------------------------ 0.8/9.3 MB 547.3 kB/s eta 0:00:16\n",
            "   --- ------------------------------------ 0.8/9.3 MB 557.7 kB/s eta 0:00:16\n",
            "   --- ------------------------------------ 0.9/9.3 MB 561.8 kB/s eta 0:00:16\n",
            "   --- ------------------------------------ 0.9/9.3 MB 562.6 kB/s eta 0:00:16\n",
            "   --- ------------------------------------ 0.9/9.3 MB 562.6 kB/s eta 0:00:16\n",
            "   --- ------------------------------------ 0.9/9.3 MB 549.1 kB/s eta 0:00:16\n",
            "   ---- ----------------------------------- 1.0/9.3 MB 563.4 kB/s eta 0:00:15\n",
            "   ---- ----------------------------------- 1.0/9.3 MB 573.4 kB/s eta 0:00:15\n",
            "   ---- ----------------------------------- 1.0/9.3 MB 579.8 kB/s eta 0:00:15\n",
            "   ---- ----------------------------------- 1.0/9.3 MB 579.8 kB/s eta 0:00:15\n",
            "   ---- ----------------------------------- 1.0/9.3 MB 579.8 kB/s eta 0:00:15\n",
            "   ---- ----------------------------------- 1.1/9.3 MB 580.7 kB/s eta 0:00:15\n",
            "   ---- ----------------------------------- 1.1/9.3 MB 586.5 kB/s eta 0:00:14\n",
            "   ---- ----------------------------------- 1.2/9.3 MB 577.8 kB/s eta 0:00:15\n",
            "   ---- ----------------------------------- 1.2/9.3 MB 577.8 kB/s eta 0:00:15\n",
            "   ----- ---------------------------------- 1.2/9.3 MB 561.8 kB/s eta 0:00:15\n",
            "   ----- ---------------------------------- 1.2/9.3 MB 573.9 kB/s eta 0:00:15\n",
            "   ----- ---------------------------------- 1.3/9.3 MB 580.3 kB/s eta 0:00:14\n",
            "   ----- ---------------------------------- 1.3/9.3 MB 580.3 kB/s eta 0:00:14\n",
            "   ----- ---------------------------------- 1.3/9.3 MB 580.3 kB/s eta 0:00:14\n",
            "   ----- ---------------------------------- 1.3/9.3 MB 570.6 kB/s eta 0:00:15\n",
            "   ----- ---------------------------------- 1.4/9.3 MB 585.0 kB/s eta 0:00:14\n",
            "   ------ --------------------------------- 1.4/9.3 MB 582.5 kB/s eta 0:00:14\n",
            "   ------ --------------------------------- 1.4/9.3 MB 587.3 kB/s eta 0:00:14\n",
            "   ------ --------------------------------- 1.4/9.3 MB 587.3 kB/s eta 0:00:14\n",
            "   ------ --------------------------------- 1.5/9.3 MB 586.1 kB/s eta 0:00:14\n",
            "   ------ --------------------------------- 1.6/9.3 MB 599.8 kB/s eta 0:00:13\n",
            "   ------ --------------------------------- 1.6/9.3 MB 600.7 kB/s eta 0:00:13\n",
            "   ------ --------------------------------- 1.6/9.3 MB 604.9 kB/s eta 0:00:13\n",
            "   ------ --------------------------------- 1.6/9.3 MB 604.9 kB/s eta 0:00:13\n",
            "   ------ --------------------------------- 1.6/9.3 MB 604.9 kB/s eta 0:00:13\n",
            "   ------- -------------------------------- 1.7/9.3 MB 615.1 kB/s eta 0:00:13\n",
            "   ------- -------------------------------- 1.8/9.3 MB 615.7 kB/s eta 0:00:13\n",
            "   ------- -------------------------------- 1.8/9.3 MB 619.7 kB/s eta 0:00:13\n",
            "   ------- -------------------------------- 1.8/9.3 MB 616.9 kB/s eta 0:00:13\n",
            "   ------- -------------------------------- 1.8/9.3 MB 616.9 kB/s eta 0:00:13\n",
            "   ------- -------------------------------- 1.8/9.3 MB 616.9 kB/s eta 0:00:13\n",
            "   ------- -------------------------------- 1.8/9.3 MB 616.9 kB/s eta 0:00:13\n",
            "   ------- -------------------------------- 1.8/9.3 MB 616.9 kB/s eta 0:00:13\n",
            "   ------- -------------------------------- 1.8/9.3 MB 616.9 kB/s eta 0:00:13\n",
            "   ------- -------------------------------- 1.8/9.3 MB 616.9 kB/s eta 0:00:13\n",
            "   ------- -------------------------------- 1.8/9.3 MB 616.9 kB/s eta 0:00:13\n",
            "   -------- ------------------------------- 2.1/9.3 MB 621.2 kB/s eta 0:00:12\n",
            "   -------- ------------------------------- 2.1/9.3 MB 621.2 kB/s eta 0:00:12\n",
            "   -------- ------------------------------- 2.1/9.3 MB 613.0 kB/s eta 0:00:12\n",
            "   --------- ------------------------------ 2.2/9.3 MB 622.5 kB/s eta 0:00:12\n",
            "   --------- ------------------------------ 2.2/9.3 MB 622.9 kB/s eta 0:00:12\n",
            "   --------- ------------------------------ 2.2/9.3 MB 623.5 kB/s eta 0:00:12\n",
            "   --------- ------------------------------ 2.2/9.3 MB 623.5 kB/s eta 0:00:12\n",
            "   --------- ------------------------------ 2.2/9.3 MB 618.4 kB/s eta 0:00:12\n",
            "   --------- ------------------------------ 2.3/9.3 MB 624.6 kB/s eta 0:00:12\n",
            "   ---------- ----------------------------- 2.3/9.3 MB 630.5 kB/s eta 0:00:12\n",
            "   ---------- ----------------------------- 2.4/9.3 MB 627.8 kB/s eta 0:00:12\n",
            "   ---------- ----------------------------- 2.4/9.3 MB 627.8 kB/s eta 0:00:12\n",
            "   ---------- ----------------------------- 2.4/9.3 MB 627.8 kB/s eta 0:00:12\n",
            "   ---------- ----------------------------- 2.5/9.3 MB 624.0 kB/s eta 0:00:12\n",
            "   ---------- ----------------------------- 2.5/9.3 MB 626.7 kB/s eta 0:00:11\n",
            "   ---------- ----------------------------- 2.5/9.3 MB 626.7 kB/s eta 0:00:11\n",
            "   ---------- ----------------------------- 2.5/9.3 MB 619.8 kB/s eta 0:00:12\n",
            "   ---------- ----------------------------- 2.6/9.3 MB 622.8 kB/s eta 0:00:11\n",
            "   ----------- ---------------------------- 2.6/9.3 MB 623.1 kB/s eta 0:00:11\n",
            "   ----------- ---------------------------- 2.6/9.3 MB 620.9 kB/s eta 0:00:11\n",
            "   ----------- ---------------------------- 2.6/9.3 MB 620.9 kB/s eta 0:00:11\n",
            "   ----------- ---------------------------- 2.6/9.3 MB 620.9 kB/s eta 0:00:11\n",
            "   ----------- ---------------------------- 2.7/9.3 MB 614.9 kB/s eta 0:00:11\n",
            "   ----------- ---------------------------- 2.7/9.3 MB 613.0 kB/s eta 0:00:11\n",
            "   ----------- ---------------------------- 2.7/9.3 MB 611.2 kB/s eta 0:00:11\n",
            "   ----------- ---------------------------- 2.7/9.3 MB 611.2 kB/s eta 0:00:11\n",
            "   ----------- ---------------------------- 2.7/9.3 MB 609.6 kB/s eta 0:00:11\n",
            "   ----------- ---------------------------- 2.8/9.3 MB 612.5 kB/s eta 0:00:11\n",
            "   ------------ --------------------------- 2.8/9.3 MB 615.1 kB/s eta 0:00:11\n",
            "   ------------ --------------------------- 2.9/9.3 MB 615.5 kB/s eta 0:00:11\n",
            "   ------------ --------------------------- 2.9/9.3 MB 615.5 kB/s eta 0:00:11\n",
            "   ------------ --------------------------- 2.9/9.3 MB 613.8 kB/s eta 0:00:11\n",
            "   ------------ --------------------------- 3.0/9.3 MB 623.0 kB/s eta 0:00:11\n",
            "   ------------ --------------------------- 3.0/9.3 MB 621.2 kB/s eta 0:00:11\n",
            "   ------------ --------------------------- 3.0/9.3 MB 623.6 kB/s eta 0:00:11\n",
            "   ------------ --------------------------- 3.0/9.3 MB 623.6 kB/s eta 0:00:11\n",
            "   ------------ --------------------------- 3.0/9.3 MB 615.7 kB/s eta 0:00:11\n",
            "   ------------- -------------------------- 3.1/9.3 MB 622.4 kB/s eta 0:00:11\n",
            "   ------------- -------------------------- 3.1/9.3 MB 626.7 kB/s eta 0:00:10\n",
            "   ------------- -------------------------- 3.2/9.3 MB 626.9 kB/s eta 0:00:10\n",
            "   ------------- -------------------------- 3.2/9.3 MB 629.2 kB/s eta 0:00:10\n",
            "   ------------- -------------------------- 3.3/9.3 MB 633.4 kB/s eta 0:00:10\n",
            "   -------------- ------------------------- 3.3/9.3 MB 635.6 kB/s eta 0:00:10\n",
            "   -------------- ------------------------- 3.3/9.3 MB 635.6 kB/s eta 0:00:10\n",
            "   -------------- ------------------------- 3.3/9.3 MB 633.9 kB/s eta 0:00:10\n",
            "   -------------- ------------------------- 3.4/9.3 MB 636.0 kB/s eta 0:00:10\n",
            "   -------------- ------------------------- 3.4/9.3 MB 640.0 kB/s eta 0:00:10\n",
            "   --------------- ------------------------ 3.5/9.3 MB 645.9 kB/s eta 0:00:10\n",
            "   --------------- ------------------------ 3.6/9.3 MB 649.7 kB/s eta 0:00:09\n",
            "   --------------- ------------------------ 3.6/9.3 MB 649.7 kB/s eta 0:00:09\n",
            "   --------------- ------------------------ 3.6/9.3 MB 651.7 kB/s eta 0:00:09\n",
            "   --------------- ------------------------ 3.6/9.3 MB 651.7 kB/s eta 0:00:09\n",
            "   --------------- ------------------------ 3.6/9.3 MB 651.7 kB/s eta 0:00:09\n",
            "   --------------- ------------------------ 3.6/9.3 MB 651.7 kB/s eta 0:00:09\n",
            "   --------------- ------------------------ 3.6/9.3 MB 651.7 kB/s eta 0:00:09\n",
            "   --------------- ------------------------ 3.6/9.3 MB 651.7 kB/s eta 0:00:09\n",
            "   ---------------- ----------------------- 3.8/9.3 MB 648.3 kB/s eta 0:00:09\n",
            "   ---------------- ----------------------- 3.9/9.3 MB 665.8 kB/s eta 0:00:09\n",
            "   ---------------- ----------------------- 3.9/9.3 MB 665.8 kB/s eta 0:00:09\n",
            "   ---------------- ----------------------- 3.9/9.3 MB 665.8 kB/s eta 0:00:09\n",
            "   ---------------- ----------------------- 3.9/9.3 MB 665.8 kB/s eta 0:00:09\n",
            "   ---------------- ----------------------- 3.9/9.3 MB 665.8 kB/s eta 0:00:09\n",
            "   ---------------- ----------------------- 4.0/9.3 MB 646.9 kB/s eta 0:00:09\n",
            "   ----------------- ---------------------- 4.0/9.3 MB 653.7 kB/s eta 0:00:09\n",
            "   ----------------- ---------------------- 4.1/9.3 MB 657.0 kB/s eta 0:00:09\n",
            "   ----------------- ---------------------- 4.1/9.3 MB 657.0 kB/s eta 0:00:09\n",
            "   ----------------- ---------------------- 4.1/9.3 MB 657.0 kB/s eta 0:00:09\n",
            "   ------------------ --------------------- 4.2/9.3 MB 668.3 kB/s eta 0:00:08\n",
            "   ------------------ --------------------- 4.3/9.3 MB 673.0 kB/s eta 0:00:08\n",
            "   ------------------ --------------------- 4.4/9.3 MB 679.3 kB/s eta 0:00:08\n",
            "   ------------------ --------------------- 4.4/9.3 MB 682.2 kB/s eta 0:00:08\n",
            "   ------------------- -------------------- 4.5/9.3 MB 685.3 kB/s eta 0:00:08\n",
            "   ------------------- -------------------- 4.5/9.3 MB 691.2 kB/s eta 0:00:07\n",
            "   ------------------- -------------------- 4.6/9.3 MB 692.5 kB/s eta 0:00:07\n",
            "   -------------------- ------------------- 4.7/9.3 MB 700.0 kB/s eta 0:00:07\n",
            "   -------------------- ------------------- 4.7/9.3 MB 700.0 kB/s eta 0:00:07\n",
            "   -------------------- ------------------- 4.7/9.3 MB 700.0 kB/s eta 0:00:07\n",
            "   -------------------- ------------------- 4.8/9.3 MB 711.1 kB/s eta 0:00:07\n",
            "   -------------------- ------------------- 4.8/9.3 MB 711.1 kB/s eta 0:00:07\n",
            "   --------------------- ------------------ 5.0/9.3 MB 720.9 kB/s eta 0:00:07\n",
            "   --------------------- ------------------ 5.0/9.3 MB 726.2 kB/s eta 0:00:06\n",
            "   --------------------- ------------------ 5.1/9.3 MB 730.5 kB/s eta 0:00:06\n",
            "   ---------------------- ----------------- 5.2/9.3 MB 734.4 kB/s eta 0:00:06\n",
            "   ---------------------- ----------------- 5.2/9.3 MB 736.5 kB/s eta 0:00:06\n",
            "   ---------------------- ----------------- 5.3/9.3 MB 737.4 kB/s eta 0:00:06\n",
            "   ---------------------- ----------------- 5.3/9.3 MB 741.6 kB/s eta 0:00:06\n",
            "   ---------------------- ----------------- 5.3/9.3 MB 741.6 kB/s eta 0:00:06\n",
            "   ---------------------- ----------------- 5.4/9.3 MB 740.2 kB/s eta 0:00:06\n",
            "   ----------------------- ---------------- 5.5/9.3 MB 749.7 kB/s eta 0:00:06\n",
            "   ----------------------- ---------------- 5.5/9.3 MB 749.7 kB/s eta 0:00:06\n",
            "   ----------------------- ---------------- 5.6/9.3 MB 752.6 kB/s eta 0:00:06\n",
            "   ------------------------ --------------- 5.7/9.3 MB 761.6 kB/s eta 0:00:05\n",
            "   ------------------------ --------------- 5.7/9.3 MB 763.9 kB/s eta 0:00:05\n",
            "   ------------------------ --------------- 5.7/9.3 MB 763.0 kB/s eta 0:00:05\n",
            "   ------------------------ --------------- 5.8/9.3 MB 764.8 kB/s eta 0:00:05\n",
            "   ------------------------- -------------- 5.8/9.3 MB 767.0 kB/s eta 0:00:05\n",
            "   ------------------------- -------------- 5.8/9.3 MB 767.0 kB/s eta 0:00:05\n",
            "   ------------------------- -------------- 5.9/9.3 MB 762.8 kB/s eta 0:00:05\n",
            "   ------------------------- -------------- 6.0/9.3 MB 771.6 kB/s eta 0:00:05\n",
            "   ------------------------- -------------- 6.0/9.3 MB 773.8 kB/s eta 0:00:05\n",
            "   -------------------------- ------------- 6.1/9.3 MB 773.9 kB/s eta 0:00:05\n",
            "   -------------------------- ------------- 6.1/9.3 MB 774.7 kB/s eta 0:00:05\n",
            "   -------------------------- ------------- 6.2/9.3 MB 777.7 kB/s eta 0:00:05\n",
            "   -------------------------- ------------- 6.3/9.3 MB 780.8 kB/s eta 0:00:04\n",
            "   --------------------------- ------------ 6.3/9.3 MB 782.6 kB/s eta 0:00:04\n",
            "   --------------------------- ------------ 6.3/9.3 MB 782.6 kB/s eta 0:00:04\n",
            "   --------------------------- ------------ 6.3/9.3 MB 782.6 kB/s eta 0:00:04\n",
            "   --------------------------- ------------ 6.3/9.3 MB 782.6 kB/s eta 0:00:04\n",
            "   --------------------------- ------------ 6.4/9.3 MB 776.2 kB/s eta 0:00:04\n",
            "   ---------------------------- ----------- 6.6/9.3 MB 791.6 kB/s eta 0:00:04\n",
            "   ---------------------------- ----------- 6.7/9.3 MB 799.2 kB/s eta 0:00:04\n",
            "   ---------------------------- ----------- 6.8/9.3 MB 807.2 kB/s eta 0:00:04\n",
            "   ----------------------------- ---------- 6.8/9.3 MB 814.0 kB/s eta 0:00:04\n",
            "   ----------------------------- ---------- 6.9/9.3 MB 820.1 kB/s eta 0:00:03\n",
            "   ------------------------------ --------- 7.1/9.3 MB 828.8 kB/s eta 0:00:03\n",
            "   ------------------------------ --------- 7.1/9.3 MB 832.7 kB/s eta 0:00:03\n",
            "   ------------------------------ --------- 7.1/9.3 MB 832.3 kB/s eta 0:00:03\n",
            "   ------------------------------ --------- 7.1/9.3 MB 832.3 kB/s eta 0:00:03\n",
            "   ------------------------------- -------- 7.3/9.3 MB 841.5 kB/s eta 0:00:03\n",
            "   ------------------------------- -------- 7.5/9.3 MB 852.3 kB/s eta 0:00:03\n",
            "   -------------------------------- ------- 7.6/9.3 MB 859.5 kB/s eta 0:00:03\n",
            "   -------------------------------- ------- 7.6/9.3 MB 864.2 kB/s eta 0:00:02\n",
            "   --------------------------------- ------ 7.7/9.3 MB 868.4 kB/s eta 0:00:02\n",
            "   --------------------------------- ------ 7.8/9.3 MB 873.4 kB/s eta 0:00:02\n",
            "   --------------------------------- ------ 7.9/9.3 MB 879.8 kB/s eta 0:00:02\n",
            "   ---------------------------------- ----- 8.0/9.3 MB 882.2 kB/s eta 0:00:02\n",
            "   ---------------------------------- ----- 8.0/9.3 MB 884.4 kB/s eta 0:00:02\n",
            "   ---------------------------------- ----- 8.0/9.3 MB 884.4 kB/s eta 0:00:02\n",
            "   ---------------------------------- ----- 8.2/9.3 MB 890.2 kB/s eta 0:00:02\n",
            "   ----------------------------------- ---- 8.3/9.3 MB 896.8 kB/s eta 0:00:02\n",
            "   ----------------------------------- ---- 8.4/9.3 MB 902.2 kB/s eta 0:00:02\n",
            "   ------------------------------------ --- 8.4/9.3 MB 906.9 kB/s eta 0:00:02\n",
            "   ------------------------------------ --- 8.5/9.3 MB 909.0 kB/s eta 0:00:01\n",
            "   ------------------------------------ --- 8.5/9.3 MB 908.0 kB/s eta 0:00:01\n",
            "   ------------------------------------ --- 8.5/9.3 MB 908.0 kB/s eta 0:00:01\n",
            "   ------------------------------------ --- 8.5/9.3 MB 908.0 kB/s eta 0:00:01\n",
            "   ------------------------------------ --- 8.5/9.3 MB 894.2 kB/s eta 0:00:01\n",
            "   ------------------------------------ --- 8.5/9.3 MB 894.2 kB/s eta 0:00:01\n",
            "   ------------------------------------ --- 8.5/9.3 MB 894.2 kB/s eta 0:00:01\n",
            "   ------------------------------------- -- 8.7/9.3 MB 901.7 kB/s eta 0:00:01\n",
            "   ------------------------------------- -- 8.9/9.3 MB 915.8 kB/s eta 0:00:01\n",
            "   -------------------------------------- - 9.0/9.3 MB 928.7 kB/s eta 0:00:01\n",
            "   -------------------------------------- - 9.0/9.3 MB 923.8 kB/s eta 0:00:01\n",
            "   -------------------------------------- - 9.1/9.3 MB 924.6 kB/s eta 0:00:01\n",
            "   ---------------------------------------  9.2/9.3 MB 928.5 kB/s eta 0:00:01\n",
            "   ---------------------------------------  9.2/9.3 MB 931.4 kB/s eta 0:00:01\n",
            "   ---------------------------------------  9.3/9.3 MB 935.2 kB/s eta 0:00:01\n",
            "   ---------------------------------------- 9.3/9.3 MB 931.2 kB/s eta 0:00:00\n",
            "Downloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
            "   ---------------------------------------- 0.0/402.6 kB ? eta -:--:--\n",
            "   -------- ------------------------------- 81.9/402.6 kB 2.2 MB/s eta 0:00:01\n",
            "   -------------- ------------------------- 143.4/402.6 kB 2.1 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 215.0/402.6 kB 1.5 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 266.2/402.6 kB 1.5 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 348.2/402.6 kB 1.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  399.4/402.6 kB 1.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 402.6/402.6 kB 1.4 MB/s eta 0:00:00\n",
            "Downloading regex-2024.5.15-cp312-cp312-win_amd64.whl (268 kB)\n",
            "   ---------------------------------------- 0.0/268.5 kB ? eta -:--:--\n",
            "   ---------------- ----------------------- 112.6/268.5 kB 6.4 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 112.6/268.5 kB 6.4 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 112.6/268.5 kB 6.4 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 112.6/268.5 kB 6.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  266.2/268.5 kB 1.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 268.5/268.5 kB 1.1 MB/s eta 0:00:00\n",
            "Downloading safetensors-0.4.3-cp312-none-win_amd64.whl (289 kB)\n",
            "   ---------------------------------------- 0.0/289.4 kB ? eta -:--:--\n",
            "   -------- ------------------------------- 61.4/289.4 kB 1.7 MB/s eta 0:00:01\n",
            "   --------- ------------------------------ 71.7/289.4 kB 1.3 MB/s eta 0:00:01\n",
            "   --------- ------------------------------ 71.7/289.4 kB 1.3 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 174.1/289.4 kB 1.1 MB/s eta 0:00:01\n",
            "   -------------------------- ----------- 204.8/289.4 kB 958.4 kB/s eta 0:00:01\n",
            "   ------------------------------ ------- 235.5/289.4 kB 901.1 kB/s eta 0:00:01\n",
            "   --------------------------------- ---- 256.0/289.4 kB 827.5 kB/s eta 0:00:01\n",
            "   -------------------------------------  286.7/289.4 kB 803.7 kB/s eta 0:00:01\n",
            "   -------------------------------------- 289.4/289.4 kB 744.4 kB/s eta 0:00:00\n",
            "Downloading tokenizers-0.19.1-cp312-none-win_amd64.whl (2.2 MB)\n",
            "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
            "   - -------------------------------------- 0.1/2.2 MB 459.5 kB/s eta 0:00:05\n",
            "   -- ------------------------------------- 0.1/2.2 MB 657.1 kB/s eta 0:00:04\n",
            "   --- ------------------------------------ 0.2/2.2 MB 696.3 kB/s eta 0:00:03\n",
            "   ---- ----------------------------------- 0.2/2.2 MB 801.7 kB/s eta 0:00:03\n",
            "   ---- ----------------------------------- 0.2/2.2 MB 754.9 kB/s eta 0:00:03\n",
            "   ----- ---------------------------------- 0.3/2.2 MB 764.6 kB/s eta 0:00:03\n",
            "   ------ --------------------------------- 0.4/2.2 MB 843.6 kB/s eta 0:00:03\n",
            "   -------- ------------------------------- 0.5/2.2 MB 930.9 kB/s eta 0:00:02\n",
            "   --------- ------------------------------ 0.5/2.2 MB 983.5 kB/s eta 0:00:02\n",
            "   --------- ------------------------------ 0.5/2.2 MB 983.5 kB/s eta 0:00:02\n",
            "   --------- ------------------------------ 0.5/2.2 MB 983.5 kB/s eta 0:00:02\n",
            "   --------- ------------------------------ 0.5/2.2 MB 983.5 kB/s eta 0:00:02\n",
            "   ------------- -------------------------- 0.7/2.2 MB 1.0 MB/s eta 0:00:02\n",
            "   -------------- ------------------------- 0.8/2.2 MB 1.0 MB/s eta 0:00:02\n",
            "   --------------- ------------------------ 0.8/2.2 MB 1.1 MB/s eta 0:00:02\n",
            "   ----------------- ---------------------- 1.0/2.2 MB 1.1 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 1.1/2.2 MB 1.2 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 1.1/2.2 MB 1.2 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 1.2/2.2 MB 1.2 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 1.2/2.2 MB 1.2 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 1.2/2.2 MB 1.2 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 1.3/2.2 MB 1.2 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 1.5/2.2 MB 1.3 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 1.6/2.2 MB 1.3 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 1.6/2.2 MB 1.3 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 1.6/2.2 MB 1.2 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 1.6/2.2 MB 1.2 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 1.7/2.2 MB 1.2 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 1.8/2.2 MB 1.2 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 1.8/2.2 MB 1.2 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 1.8/2.2 MB 1.2 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 1.8/2.2 MB 1.2 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 1.8/2.2 MB 1.2 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 1.9/2.2 MB 1.2 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 1.9/2.2 MB 1.1 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 1.9/2.2 MB 1.1 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 1.9/2.2 MB 1.1 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 2.0/2.2 MB 1.1 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 2.0/2.2 MB 1.1 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 2.0/2.2 MB 1.1 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 2.0/2.2 MB 1.0 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 2.0/2.2 MB 1.0 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 2.0/2.2 MB 1.0 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 2.1/2.2 MB 1.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.2/2.2 MB 1.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.2/2.2 MB 997.3 kB/s eta 0:00:01\n",
            "   ---------------------------------------  2.2/2.2 MB 992.6 kB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.2/2.2 MB 979.7 kB/s eta 0:00:00\n",
            "Installing collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.22.2\n",
            "    Uninstalling huggingface-hub-0.22.2:\n",
            "      Successfully uninstalled huggingface-hub-0.22.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python312\\\\site-packages\\\\transformers\\\\models\\\\deprecated\\\\trajectory_transformer\\\\convert_trajectory_transformer_original_pytorch_checkpoint_to_pytorch.py'\n",
            "HINT: This error might have occurred since this system does not have Windows Long Path support enabled. You can find information on how to enable this at https://pip.pypa.io/warnings/enable-long-paths\n",
            "\n",
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
            "[notice] To update, run: C:\\Users\\ADMIN\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mpg27wbUGo0c"
      },
      "outputs": [],
      "source": [
        "# import tensorflow_hub as hub\n",
        "\n",
        "# module_path = 'https://tfhub.dev/deepmind/biggan-256/2'  # BigGAN-256 TFHub module\n",
        "# model = hub.load(module_path)\n",
        "\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# # from tensorflow.keras.models import load_model\n",
        "\n",
        "# # # Function to load BigGAN model (replace with your model path)\n",
        "# # def load_biggan_model(model_path):\n",
        "# #   model = load_model(model_path)\n",
        "# #   return model\n",
        "\n",
        "# # Function to preprocess video frame (adjust based on BigGAN input requirements)\n",
        "# def preprocess_frame(frame):\n",
        "#   # Resize, normalize, or apply other transformations\n",
        "#   frame = cv2.resize(frame, (256, 256))  # Example resize to 256x256\n",
        "#   frame = frame / 255.0  # Example normalization\n",
        "#   return frame\n",
        "\n",
        "# # Function to generate animation frame using BigGAN\n",
        "# def generate_animation_frame(model, noise):\n",
        "#   latent = model.layers[1](noise)  # Assuming first layer handles noise\n",
        "#   img = model.predict(latent)\n",
        "#   return img[0]  # Assuming model outputs a batch of images\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#   # # Load BigGAN model\n",
        "#   # model = load_biggan_model(\"path/to/biggan_model.h5\")\n",
        "\n",
        "#   # Specify input and output video paths\n",
        "#   input_video_path = \"/content/2.mp4\"\n",
        "#   output_video_path = \"/content/output_animation.mp4\"\n",
        "\n",
        "#   # Open video capture\n",
        "#   cap = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "#   # Process each frame (consider error handling)\n",
        "#   processed_frames = []\n",
        "#   while True:\n",
        "#     ret, frame = cap.read()\n",
        "#     if not ret:\n",
        "#       break\n",
        "\n",
        "#     # Preprocess frame\n",
        "#     preprocessed_frame = preprocess_frame(frame)\n",
        "\n",
        "#     # Generate random noise for BigGAN\n",
        "#     noise = np.random.randn(1, model.layers[1].input_shape[1])\n",
        "\n",
        "#     # Generate animation frame\n",
        "#     animation_frame = generate_animation_frame(model, noise)\n",
        "\n",
        "#     # Optionally, post-process animation frame (e.g., color correction)\n",
        "\n",
        "#     processed_frames.append(animation_frame.astype(np.uint8))  # Convert back to uint8 for video writing\n",
        "\n",
        "#   cap.release()\n",
        "\n",
        "#   # Create output video (adjust FPS and other parameters as needed)\n",
        "#   fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # Change codec if needed\n",
        "#   out = cv2.VideoWriter(output_video_path, fourcc, 24.0, (animation_frame.shape[1], animation_frame.shape[0]))\n",
        "#   for frame in processed_frames:\n",
        "#     out.write(frame)\n",
        "#   out.release()\n",
        "\n",
        "#   print(\"Animation video created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "d73QuKANG6kX"
      },
      "outputs": [],
      "source": [
        "# import tensorflow_hub as hub\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "\n",
        "# # Load TFHub BigGAN module\n",
        "# module_path = 'https://tfhub.dev/deepmind/biggan-256/2'\n",
        "# model = hub.load(module_path)\n",
        "\n",
        "# # Preprocess video frame (adjust as needed for BigGAN input requirements)\n",
        "# def preprocess_frame(frame):\n",
        "#   frame = cv2.resize(frame, (256, 256))  # Resize to module's input size\n",
        "#   frame = frame / 255.0  # Normalize\n",
        "#   return frame\n",
        "\n",
        "# # Generate animation frame using BigGAN TFHub module\n",
        "# def generate_animation_frame(model, noise):\n",
        "#   # TFHub modules typically expect preprocessing within the module itself\n",
        "#   img = model(noise)[0]  # Directly generate image from noise\n",
        "#   return img\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#   input_video_path = \"/content/2.mp4\"\n",
        "#   output_video_path = \"/content/output_animation.mp4\"\n",
        "\n",
        "#   cap = cv2.VideoCapture(input_video_path)\n",
        "#   processed_frames = []\n",
        "\n",
        "#   while True:\n",
        "#     ret, frame = cap.read()\n",
        "#     if not ret:\n",
        "#       break\n",
        "\n",
        "#     preprocessed_frame = preprocess_frame(frame)\n",
        "#     noise = np.random.randn(1, 128)  # Adjust noise dimensions based on module requirements\n",
        "#     animation_frame = generate_animation_frame(model, noise)\n",
        "#     processed_frames.append(animation_frame.astype(np.uint8))\n",
        "\n",
        "#   cap.release()\n",
        "\n",
        "#   fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "#   out = cv2.VideoWriter(output_video_path, fourcc, 24.0, (256, 256))  # Match output size to module\n",
        "#   for frame in processed_frames:\n",
        "#     out.write(frame)\n",
        "#   out.release()\n",
        "\n",
        "#   print(\"Animation video created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yHZsjX1wNRvd"
      },
      "outputs": [],
      "source": [
        "# !pip install opencv-python moviepy stylegan2-pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tUOKZPSmJ5fs"
      },
      "outputs": [],
      "source": [
        "# import cv2\n",
        "\n",
        "# # Load pre-trained pose estimation model (replace with your preferred model)\n",
        "# # net = cv2.dnn.readNetFromCaffe(\"/content/pose_deploy.prototxt\", \"path/to/pose_model.caffemodel\")\n",
        "# net = cv2.dnn.readNetFromCaffe(\"/content/pose_deploy.prototxt\", \"/content/pose_iter_440000.caffemodel\")\n",
        "\n",
        "\n",
        "# def estimate_pose(frame):\n",
        "#   # Preprocess frame (resize, normalization, etc.)\n",
        "#   blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), (10.0, 10.0, 10.0), swapRB=True, crop=False)\n",
        "#   net.setInput(blob)\n",
        "#   detections = net.forward()\n",
        "\n",
        "#   # Parse detections and extract keypoints (modify based on model output)\n",
        "#   keypoints = []\n",
        "#   for i in range(detections.shape[0]):\n",
        "#     confidence = detections[i, 2]\n",
        "#     if confidence > 0.5:\n",
        "#       x = detections[i, 3] * frame.shape[1]\n",
        "#       y = detections[i, 4] * frame.shape[0]\n",
        "#       keypoints.append((int(x), int(y)))\n",
        "#   return keypoints\n",
        "# from stylegan2_pytorch import StyleGAN2\n",
        "\n",
        "# # Load pre-trained StyleGAN2 generator (replace with your desired style)\n",
        "# generator = StyleGAN2.load_generator(\"path/to/stylegan2-ffhq-config.yaml\")\n",
        "\n",
        "# def generate_animation_frame(noise):\n",
        "#   # Generate an image from random noise\n",
        "#   latent = generator.style_mod.get_style_from_noise(noise)\n",
        "#   img = generator(latent)\n",
        "#   return img.detach().cpu().numpy()[0]\n",
        "# import cv2\n",
        "# from moviepy.editor import VideoFileClip\n",
        "\n",
        "# def process_video(input_video_path, output_video_path, animation_style, fps=24):\n",
        "#   # Load video\n",
        "#   clip = VideoFileClip(input_video_path)\n",
        "\n",
        "#   # Process each frame (consider pose estimation integration here)\n",
        "#   processed_frames = []\n",
        "#   for frame in clip.iter_frames():\n",
        "#     # Optionally, extract human pose here\n",
        "#     # keypoints = estimate_pose(frame)\n",
        "\n",
        "#     # Generate animation frame with style transfer\n",
        "#     noise = np.random.randn(1, generator.z_dim)\n",
        "#     animation_frame = generate_animation_frame(noise)\n",
        "\n",
        "#     # Optionally, adjust animation frame based on pose (e.g., warping)\n",
        "\n",
        "#     processed_frames.append(animation_frame)\n",
        "\n",
        "#   # Create output video with desired FPS\n",
        "#   new_clip = VideoFileClip(processed_frames, fps=fps)\n",
        "#   new_clip.write_videofile(output_video_path)\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#   input_video_path = \"/content/2.mp4\"\n",
        "#   output_video_path = \"/content/output_animation.mp4\"\n",
        "#   animation_style = \"path/to/stylegan2-ffhq-config.yaml\"  # Replace with your style\n",
        "#   process_video(input_video_path, output_video_path, animation_style)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3YqOaOxJNXPT"
      },
      "outputs": [],
      "source": [
        "# # https://huggingface.co/sayakpaul/whitebox-cartoonizer\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# import requests\n",
        "# import tensorflow as tf\n",
        "# from huggingface_hub import snapshot_download\n",
        "# from PIL import Image\n",
        "\n",
        "\n",
        "# def resize_crop(image):\n",
        "#     h, w, c = np.shape(image)\n",
        "#     if min(h, w) > 720:\n",
        "#         if h > w:\n",
        "#             h, w = int(720 * h / w), 720\n",
        "#         else:\n",
        "#             h, w = 720, int(720 * w / h)\n",
        "#     image = cv2.resize(image, (w, h), interpolation=cv2.INTER_AREA)\n",
        "#     h, w = (h // 8) * 8, (w // 8) * 8\n",
        "#     image = image[:h, :w, :]\n",
        "#     return image\n",
        "\n",
        "\n",
        "# def download_image(url):\n",
        "#     image = Image.open(requests.get(url, stream=True).raw)\n",
        "#     image = image.convert(\"RGB\")\n",
        "#     image = np.array(image)\n",
        "#     image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "#     return image\n",
        "\n",
        "\n",
        "# def preprocess_image(image):\n",
        "#     image = resize_crop(image)\n",
        "#     image = image.astype(np.float32) / 127.5 - 1\n",
        "#     image = np.expand_dims(image, axis=0)\n",
        "#     image = tf.constant(image)\n",
        "#     return image\n",
        "\n",
        "\n",
        "# # Load the model and extract concrete function.\n",
        "# model_path = snapshot_download(\"sayakpaul/whitebox-cartoonizer\")\n",
        "# loaded_model = tf.saved_model.load(model_path)\n",
        "# concrete_func = loaded_model.signatures[\"serving_default\"]\n",
        "\n",
        "# # # Download and preprocess image.\n",
        "# # image_url = \"https://huggingface.co/spaces/sayakpaul/cartoonizer-demo-onnx/resolve/main/mountain.jpeg\"\n",
        "# # image = download_image(image_url)\n",
        "# image = cv2.imread(\"/content/swapped00a012.jpg\")\n",
        "# preprocessed_image = preprocess_image(image)\n",
        "\n",
        "# # Run inference.\n",
        "# result = concrete_func(preprocessed_image)[\"final_output:0\"]\n",
        "\n",
        "# # Post-process the result and serialize it.\n",
        "# output = (result[0].numpy() + 1.0) * 127.5\n",
        "# output = np.clip(output, 0, 255).astype(np.uint8)\n",
        "# output = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)\n",
        "# output_image = Image.fromarray(output)\n",
        "# output_image.save(\"result.jpeg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KTTMum_zQ_bl"
      },
      "outputs": [],
      "source": [
        "# # https://huggingface.co/sayakpaul/whitebox-cartoonizer\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# import requests\n",
        "# import tensorflow as tf\n",
        "# from huggingface_hub import snapshot_download\n",
        "# from PIL import Image\n",
        "\n",
        "\n",
        "# def resize_crop(image):\n",
        "#     h, w, c = np.shape(image)\n",
        "#     if min(h, w) > 720:\n",
        "#         if h > w:\n",
        "#             h, w = int(720 * h / w), 720\n",
        "#         else:\n",
        "#             h, w = 720, int(720 * w / h)\n",
        "#     image = cv2.resize(image, (w, h), interpolation=cv2.INTER_AREA)\n",
        "#     h, w = (h // 8) * 8, (w // 8) * 8\n",
        "#     image = image[:h, :w, :]\n",
        "#     return image\n",
        "\n",
        "\n",
        "# def download_image(url):\n",
        "#     image = Image.open(requests.get(url, stream=True).raw)\n",
        "#     image = image.convert(\"RGB\")\n",
        "#     image = np.array(image)\n",
        "#     image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "#     return image\n",
        "\n",
        "\n",
        "# def preprocess_image(image):\n",
        "#     image = resize_crop(image)\n",
        "#     image = image.astype(np.float32) / 127.5 - 1\n",
        "#     image = np.expand_dims(image, axis=0)\n",
        "#     image = tf.constant(image)\n",
        "#     return image\n",
        "\n",
        "\n",
        "# # Load the model and extract concrete function.\n",
        "# model_path = snapshot_download(\"sayakpaul/whitebox-cartoonizer\")\n",
        "# loaded_model = tf.saved_model.load(model_path)\n",
        "# concrete_func = loaded_model.signatures[\"serving_default\"]\n",
        "\n",
        "# # # Download and preprocess image.\n",
        "# # image_url = \"https://huggingface.co/spaces/sayakpaul/cartoonizer-demo-onnx/resolve/main/mountain.jpeg\"\n",
        "# # image = download_image(image_url)\n",
        "# image = cv2.VideoCapture(\"/content/London Trip on Winter - Made with Clipchamp.mp4\")\n",
        "# preprocessed_image = preprocess_image(image)\n",
        "\n",
        "# # Run inference.\n",
        "# result = concrete_func(preprocessed_image)[\"final_output:0\"]\n",
        "\n",
        "# # Post-process the result and serialize it.\n",
        "# output = (result[0].numpy() + 1.0) * 127.5\n",
        "# output = np.clip(output, 0, 255).astype(np.uint8)\n",
        "# output = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)\n",
        "# output_image = Image.fromarray(output)\n",
        "# output_image.save(\"result1.jpeg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogtw45dR_TXg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HJF6Q-k_T53"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24QLJu3P-ZbU"
      },
      "source": [
        "# YOUTUBE VIDEO DOWNLOADING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-DM0_tq-aNh",
        "outputId": "b87f8576-7074-4314-db19-5db5d6d56399"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytube in c:\\users\\admin\\anaconda3\\lib\\site-packages (15.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytube\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VauBiCMloWGm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqXIkN1Y-ap6",
        "outputId": "eadf7424-2dcc-450f-b370-aa2b71b871e4"
      },
      "outputs": [],
      "source": [
        "# uncomment total only local video extraction\n",
        "# # # Import libraries\n",
        "# # import pytube\n",
        "\n",
        "# # # Define function to download video\n",
        "# # def download_video(url, output_path=\".\"):\n",
        "# #   \"\"\"Downloads a YouTube video to the specified output path.\n",
        "\n",
        "# #   Args:\n",
        "# #       url: The URL of the YouTube video to download.\n",
        "# #       output_path: The path to save the downloaded video (optional).\n",
        "# #   \"\"\"\n",
        "# #   try:\n",
        "# #     # Create a YouTube object\n",
        "# #     youtube = pytube.YouTube(url)\n",
        "\n",
        "# #     # Get the highest resolution stream (modify for specific resolution if needed)\n",
        "# #     video_stream = youtube.streams.get_highest_resolution()\n",
        "\n",
        "# #     # Download the video\n",
        "# #     video_stream.download(output_path=output_path)\n",
        "\n",
        "# #     print(\"Video downloaded successfully!\")\n",
        "# #   except Exception as e:\n",
        "# #     print(f\"An error occurred: {e}\")\n",
        "\n",
        "# # # Example usage\n",
        "# # video_url = \"https://www.youtube.com/watch?v=gtw2T55VXQQ\"  # Replace with your desired video URL\n",
        "# # download_video(video_url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pytube\n",
        "\n",
        "def download_video(url, output_path=\".\"):\n",
        "    \"\"\"Downloads a YouTube video to the specified output path and returns the file path.\n",
        "\n",
        "    Args:\n",
        "        url: The URL of the YouTube video to download.\n",
        "        output_path: The path to save the downloaded video (optional).\n",
        "\n",
        "    Returns:\n",
        "        The file path of the downloaded video.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Create a YouTube object\n",
        "        youtube = pytube.YouTube(url)\n",
        "\n",
        "        # Get the highest resolution stream (modify for specific resolution if needed)\n",
        "        video_stream = youtube.streams.get_highest_resolution()\n",
        "\n",
        "        # Download the video and get the file path\n",
        "        file_path = video_stream.download(output_path=output_path)\n",
        "\n",
        "        print(f\"Video downloaded successfully! File path: {file_path}\")\n",
        "        return file_path\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "# Example usage\n",
        "video_url = \"https://youtu.be/ir12Boxh__Q\"  # Replace with your desired video URL\n",
        "downloaded_file_path = download_video(video_url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iZywqrp-a7N"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNUCgnf1_SjD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTUTMBJFw-lg"
      },
      "source": [
        "# YOUTUBE AUDIO DOWNLOADING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: moviepy in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from moviepy) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from moviepy) (1.26.4)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from moviepy) (2.34.2)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from imageio<3.0,>=2.5->moviepy) (10.3.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from imageio-ffmpeg>=0.2.0->moviepy) (69.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2024.2.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm<5.0,>=4.11.2->moviepy) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
            "[notice] To update, run: C:\\Users\\ADMIN\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install moviepy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlSlvXT2REuT",
        "outputId": "4495dd01-5c8c-45b3-ec42-540fd6bd99fa"
      },
      "outputs": [],
      "source": [
        "# uncomment total only local video extraction\n",
        "# # from moviepy.editor import VideoFileClip\n",
        "\n",
        "# # def extract_audio(video_path, output_path):\n",
        "# #   \"\"\"Extracts audio from a video and saves it as a separate MP3 file.\n",
        "\n",
        "# #   Args:\n",
        "# #       video_path: Path to the video file.\n",
        "# #       output_path: Path to save the extracted audio file (MP3 format).\n",
        "# #   \"\"\"\n",
        "# #   video = VideoFileClip(video_path)\n",
        "# #   audio = video.audio.write_audiofile(output_path)\n",
        "# #   print(f\"Audio extracted and saved to: {output_path}\")\n",
        "\n",
        "# # # Example usage\n",
        "# # video_path = \"/content/Pushpa 2 The Rule Teaser  Allu Arjun  Sukumar  Rashmika Mandanna  Fahadh Faasil  DSP.mp4\"  # Replace with your video path\n",
        "\n",
        "# # audio_path = \"extracted_audio.mp3\"  # Adjust the output path\n",
        "# # extract_audio(video_path, audio_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "aM_JMHm91J6X"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'split'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[19], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# video_path = \"/content/Pushpa 2 The Rule Teaser  Allu Arjun  Sukumar  Rashmika Mandanna  Fahadh Faasil  DSP.mp4\"  # Replace with your video path\u001b[39;00m\n\u001b[0;32m     16\u001b[0m video_path \u001b[38;5;241m=\u001b[39m downloaded_file_path\n\u001b[1;32m---> 17\u001b[0m audio_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdownloaded_file_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_extracted_audio.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Adjust the output path\u001b[39;00m\n\u001b[0;32m     18\u001b[0m extract_audio(video_path, audio_path)\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
          ]
        }
      ],
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "def extract_audio(video_path, output_path):\n",
        "  \"\"\"Extracts audio from a video and saves it as a separate MP3 file.\n",
        "\n",
        "  Args:\n",
        "      video_path: Path to the video file.\n",
        "      output_path: Path to save the extracted audio file (MP3 format).\n",
        "  \"\"\"\n",
        "  video = VideoFileClip(video_path)\n",
        "  audio = video.audio.write_audiofile(output_path)\n",
        "  print(f\"Audio extracted and saved to: {output_path}\")\n",
        "\n",
        "# Example usage\n",
        "# video_path = \"/content/Pushpa 2 The Rule Teaser  Allu Arjun  Sukumar  Rashmika Mandanna  Fahadh Faasil  DSP.mp4\"  # Replace with your video path\n",
        "video_path = downloaded_file_path\n",
        "audio_path = f\"{downloaded_file_path.split(\"/\")[-1]}_extracted_audio.mp3\"  # Adjust the output path\n",
        "extract_audio(video_path, audio_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc9UMWWBmFt0"
      },
      "source": [
        "# breaking the video , editing, joining\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pE3rMR1o_RZc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-FR4EZBS_Qqn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: opencv-python in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (4.9.0.80)\n",
            "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from opencv-python) (1.26.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
            "[notice] To update, run: C:\\Users\\ADMIN\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: huggingface_hub in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (0.23.4)\n",
            "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.31.0)\n",
            "Requirement already satisfied: pillow in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (10.3.0)\n",
            "Collecting tensorflow\n",
            "  Using cached tensorflow-2.16.2-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface_hub) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface_hub) (2024.3.1)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface_hub) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface_hub) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface_hub) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests) (2024.2.2)\n",
            "Collecting tensorflow-intel==2.16.2 (from tensorflow)\n",
            "  Using cached tensorflow_intel-2.16.2-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (4.25.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (69.5.1)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.62.2)\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.16.2)\n",
            "Requirement already satisfied: keras>=3.0.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.26.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.2->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (0.11.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (2.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (0.1.2)\n",
            "Using cached tensorflow-2.16.2-cp312-cp312-win_amd64.whl (2.1 kB)\n",
            "Using cached tensorflow_intel-2.16.2-cp312-cp312-win_amd64.whl (377.1 MB)\n",
            "Installing collected packages: tensorflow-intel, tensorflow\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python312\\\\site-packages\\\\tensorflow\\\\include\\\\external\\\\com_github_grpc_grpc\\\\src\\\\core\\\\ext\\\\filters\\\\client_channel\\\\lb_policy\\\\grpclb\\\\client_load_reporting_filter.h'\n",
            "HINT: This error might have occurred since this system does not have Windows Long Path support enabled. You can find information on how to enable this at https://pip.pypa.io/warnings/enable-long-paths\n",
            "\n",
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
            "[notice] To update, run: C:\\Users\\ADMIN\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub requests pillow tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470,
          "referenced_widgets": [
            "30c1561e707d4d8286ca6a643e54590f",
            "9204b71e33df4dc9980b5a1a11f5720f",
            "a9d0a251d3bb4f60bc80d0100da51bea",
            "be724d16178040068ef23f6de6dbdd95",
            "6801f06aa0d2467cb31b93f961eb9a5a",
            "d2c79bbdbbeb4424a105c7599bead272",
            "c923ee2a94fb47018262a160e8451ec9",
            "ac4264146375477ab1bc2cc51c3f3f0a",
            "6a050c27907647d7957c08f4622b3239",
            "7150b1a4491a49ffb76a9c51788c1e11",
            "a0664d158e20430db1bb60cc2d7f185b",
            "1ec8385fae664d8fb94e292d4e78e1cb",
            "138f95e24b3440de8c24729862953298",
            "e0c80050023f466bac0c8e9b371f0b5b",
            "697ed0d812e44b0a85c7dcd8ab4b09fb",
            "f40c037a4388487a91600a9250c8d2b8",
            "801c12b0a6ab4e138522e3de45f659e2",
            "466802cd5bed4a0daaed6386c4f1892d",
            "8e1463f4a7074b3ca56b435e9e29d4f3",
            "2343eed89b2d4410ab729d5d3610bc6c",
            "c2bf5b63b0504d65b448359e48335134",
            "94accabc37f642d493e14d76d018a86d",
            "2797dfe6a61b4a209930fc6f2413211f",
            "9a3373a99c7f4f54bbfba15e73f27935",
            "2cce0fe43b624a518883be8eed8f34c8",
            "6a32d7a3770244dd8770f5874434c5b2",
            "f7d4002dc5474b248fc7b7177081d2e2",
            "f7ffb1e648cc40d78b3685f451115841",
            "73d5f6b599dc4356afe0db3fd370ed73",
            "78f25e7802e14051b967f37193dab465",
            "f029ea9cfb5b4330af25157968b0084d",
            "7554b6ffc5394e6bab1a8805f6f92b6b",
            "ced77bb7976747e18b76530bcaa4d6c6",
            "392eceb2f8004931a08834b8adf99d58",
            "c858ae4afc0c4e7292f951cf5894e288",
            "10526fa1368444e38cc56193d93b4d89",
            "3791e7d6dd3f4fe6829b6db0a3087410",
            "b8dac3a2723f4b48b1e2a42fb80af21a",
            "db49cdd3be8c46a4b18e04aae9faf9eb",
            "b3a0b6f84b1b4065a3a849afc67b4707",
            "9c244c90a1de42f6b108979bac5d6951",
            "e50248c836e54fa7b2ba108555b63afe",
            "9b118740a4d14c1eaeb5569153497a28",
            "735a535de3ec4c4e91f241d7d72fcac0",
            "9ce54d6bc5b94bf0b1451ba29a68a031",
            "811de8da95334fc480e6534fd81658e5",
            "fb0d852a0170492d9bb49f891bb05003",
            "dc523ea5287d482091ced0439a773404",
            "680fc3a1e76a4b7a980b877c35b1fad4",
            "3c880954be7b4fbe80690722a0d925a4",
            "2bf3e7e5d41d4ee6a06eb7a85c6970ff",
            "8b2c7c1e656c47b48501883d06cf3a40",
            "8631ea8151d34fe1b478a7aa9665c2f5",
            "cf32f42df2594049ac647efa635cdfa8",
            "09ea73a133e84659aa1bdb89f9e06be2",
            "59f9c21439d1429aa378618eacf3b3cf",
            "623ad51220a941efbef63ee3ac7ac13e",
            "0d971e89d4af4924b16d8fefd7763506",
            "9dbe518d3ff146b18b4ad76aa1d3cea2",
            "10dfddd8aeb447b9a728819f19f19db6",
            "92080f9d7d944b50968d9bb7f0ffd62a",
            "c26be6e5f4eb4839b0c0da2d252b43ce",
            "73c1c3ca5a514a4b872ec0cada1a837b",
            "c0ef27fa4ecb491aa44deb9c3a0ea29b",
            "53bb48c0c1c040f78952201729e9ce16",
            "30c97ef9e70542219966f139617911e0",
            "0f9fe2c24c56479bb7f23d557114f5e5",
            "e540d93d806f4ef4917d8212ffb59f09",
            "5563fafa006f4f1a95b2d8cab2e83131",
            "bac2b959dd48467999e4de0a35e40f46",
            "485d637bb10a40a6b036bb92216d6e02",
            "2d1ca86022ea45bb8755e955fd66f95f",
            "a9ca8b9ac51c4d5c93ac8c320ef95435",
            "b5b290bdc453402899b0ff584d4e0102",
            "6a9d2f163d1e49149fb02decc9c6db51",
            "235010e5be824fc78c437798919b7aff",
            "5eb4b2df28984870baa386fe4851f2aa",
            "df4ddfdbafc94945a5234d81a62577c1",
            "18da201f07e44ba69ac5f234ed431d52",
            "a577405ea4be42ae88186491d7b91280",
            "88b4856bbd594e88a6bfe283d43e39fa",
            "1f07c99bc3e24846b65d2060ffa1bf44",
            "4e6ccaec1f80421389b87c78673043a4",
            "d00f9b5d11644039b239e870f0db164f",
            "1353f0ea70ed47949a8b261713b7495c",
            "a378d93f454544bb9df4c6add809fcd0",
            "42143cd120134cc3974f2756c58ece42",
            "8d158654702141aca827157557af3eaa"
          ]
        },
        "id": "kJ-5sYyVqEnj",
        "outputId": "8a46028e-a465-4bb8-c1a3-6671637dd2b9"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow.python'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m snapshot_download\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\__init__.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msite\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_site\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python'"
          ]
        }
      ],
      "source": [
        "# https://huggingface.co/sayakpaul/whitebox-cartoonizer\n",
        "# 2.1\n",
        "import cv2\n",
        "import numpy as np\n",
        "import requests\n",
        "import tensorflow as tf\n",
        "from huggingface_hub import snapshot_download\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def resize_crop(image):\n",
        "    h, w, c = np.shape(image)\n",
        "    if min(h, w) > 720:\n",
        "        if h > w:\n",
        "            h, w = int(720 * h / w), 720\n",
        "        else:\n",
        "            h, w = 720, int(720 * w / h)\n",
        "    image = cv2.resize(image, (w, h), interpolation=cv2.INTER_AREA)\n",
        "    h, w = (h // 8) * 8, (w // 8) * 8\n",
        "    image = image[:h, :w, :]\n",
        "    return image\n",
        "\n",
        "\n",
        "# def download_image(url):\n",
        "#     image = Image.open(requests.get(url, stream=True).raw)\n",
        "#     image = image.convert(\"RGB\")\n",
        "#     image = np.array(image)\n",
        "#     image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "#     return image\n",
        "\n",
        "\n",
        "def preprocess_image(image):\n",
        "    image = resize_crop(image)\n",
        "    image = image.astype(np.float32) / 127.5 - 1\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    image = tf.constant(image)\n",
        "    return image\n",
        "\n",
        "\n",
        "# Load the model and extract concrete function.\n",
        "model_path = snapshot_download(\"sayakpaul/whitebox-cartoonizer\")\n",
        "loaded_model = tf.saved_model.load(model_path)\n",
        "concrete_func = loaded_model.signatures[\"serving_default\"]\n",
        "\n",
        "# # # Download and preprocess image.\n",
        "# # image_url = \"https://huggingface.co/spaces/sayakpaul/cartoonizer-demo-onnx/resolve/main/mountain.jpeg\"\n",
        "# # image = download_image(image_url)\n",
        "# image = cv2.imread(\"/content/2.png\")\n",
        "# preprocessed_image = preprocess_image(image)\n",
        "\n",
        "# # Run inference.\n",
        "# result = concrete_func(preprocessed_image)[\"final_output:0\"]\n",
        "\n",
        "# # Post-process the result and serialize it.\n",
        "# output = (result[0].numpy() + 1.0) * 127.5\n",
        "# output = np.clip(output, 0, 255).astype(np.uint8)\n",
        "# output = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)\n",
        "# output_image = Image.fromarray(output)\n",
        "# output_image.save(\"result1.jpeg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60FjWmDHmKa7",
        "outputId": "52e7a390-b1c9-4350-8622-2f151b988583"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error opening video file: /content/Pushpa 2 The Rule Teaser  Allu Arjun  Sukumar  Rashmika Mandanna  Fahadh Faasil  DSP.mp4\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# 1.1\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def extract_images(video_path, output_dir, target_fps=30):\n",
        "  \"\"\"Extracts images from a video at the specified target frame rate.\n",
        "\n",
        "  Args:\n",
        "      video_path (str): Path to the input video file.\n",
        "      output_dir (str): Path to the output directory for extracted images.\n",
        "      target_fps (int, optional): Target frame rate for extracted images. Defaults to 30.\n",
        "  \"\"\"\n",
        "\n",
        "  # Create the output directory if it doesn't exist\n",
        "  os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "  # Open the video capture object\n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "  # Check if video was opened successfully\n",
        "  if not cap.isOpened():\n",
        "    print(\"Error opening video file:\", video_path)\n",
        "    return\n",
        "\n",
        "  # Get the original video frame rate\n",
        "  original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "  # Calculate the frame step for the target fps\n",
        "  frame_step = int(max(1, round(original_fps / target_fps)))\n",
        "\n",
        "  # Count frames and image index\n",
        "  frame_count = 0\n",
        "  image_index = 0\n",
        "\n",
        "  while True:\n",
        "    # Capture frame-by-frame\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if not ret:\n",
        "      # End of video\n",
        "      break\n",
        "\n",
        "    # Extract image at the specified frame step interval\n",
        "    if frame_count % frame_step == 0:\n",
        "      # Create image filename with zero-padding\n",
        "      image_name = f\"image_{image_index:05d}.png\"  # Adjust extension as needed (jpg, etc.)\n",
        "      image_path = os.path.join(output_dir, image_name)\n",
        "\n",
        "      # Save the extracted image\n",
        "      cv2.imwrite(image_path, frame)\n",
        "      image_index += 1\n",
        "      if image_index % 50 == 0:\n",
        "        print(image_index)\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "  # Release the video capture object\n",
        "  cap.release()\n",
        "  print(\"Images extracted successfully!\")\n",
        "\n",
        "# Example usage\n",
        "# Replace with your video path and desired output directory\n",
        "# video_path = \"/content/Pushpa 2 The Rule Teaser  Allu Arjun  Sukumar  Rashmika Mandanna  Fahadh Faasil  DSP.mp4\"\n",
        "video_path = video_path\n",
        "output_dir = \"extracted_images\"\n",
        "\n",
        "extract_images(video_path, output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBGECeB3CHA8"
      },
      "outputs": [],
      "source": [
        "# # 1.2\n",
        "# import cv2\n",
        "# import wave\n",
        "# import numpy as np\n",
        "# def extract_audio(video_path, output_filename=\"output.wav\"):\n",
        "#   \"\"\"Extracts audio from a video and saves it to a WAV file.\n",
        "\n",
        "#   Args:\n",
        "#       video_path (str): Path to the input video file.\n",
        "#       output_filename (str, optional): Filename for the saved audio file. Defaults to \"output.wav\".\n",
        "#   \"\"\"\n",
        "\n",
        "#   # Open the video capture object\n",
        "#   cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "#   # Check if video was opened successfully\n",
        "#   if not cap.isOpened():\n",
        "#     print(\"Error opening video file:\", video_path)\n",
        "#     return\n",
        "\n",
        "#   # Create audio recording object\n",
        "#   audio_out = wave.open(output_filename, 'wb')\n",
        "\n",
        "#   # Get video properties (assuming audio sample rate matches video FPS)\n",
        "#   audio_fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "#   audio_channels = 2  # Adjust for stereo or mono\n",
        "#   audio_sample_rate = audio_fps\n",
        "\n",
        "#   # Set audio recording parameters\n",
        "#   audio_out.setnchannels(audio_channels)\n",
        "#   audio_out.setsampwidth(2)  # Assuming 16-bit audio (2 bytes per sample)\n",
        "#   audio_out.setframerate(audio_sample_rate)\n",
        "\n",
        "#   while True:\n",
        "#     # Capture frame-by-frame\n",
        "#     ret, frame = cap.read()\n",
        "\n",
        "#     if not ret:\n",
        "#       # End of video\n",
        "#       break\n",
        "\n",
        "#     # Read audio data (adjust buffer size if needed)\n",
        "#     audio_data = cap.read(1)[1]\n",
        "\n",
        "#     # Check if audio data exists and write to file\n",
        "#     if np.any(audio_data):\n",
        "#       audio_out.writeframes(audio_data)\n",
        "\n",
        "#   # Release resources\n",
        "#   cap.release()\n",
        "#   audio_out.close()\n",
        "\n",
        "#   print(\"Audio extracted successfully!\")\n",
        "\n",
        "# # Example usage\n",
        "# # video_path = \"path/to/your/video.mp4\"\n",
        "# video_path = \"/content/2.mp4\"\n",
        "# output_filename=\"output.wav\"\n",
        "# extract_audio(video_path,output_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_Y1EoUr5zd2"
      },
      "outputs": [],
      "source": [
        "# # 1.3\n",
        "# import cv2\n",
        "# import wave\n",
        "\n",
        "# def extract_audio_to_mp3(video_path, output_path=\"audio.mp3\"):\n",
        "#   \"\"\"Extracts audio from a video and saves it as an MP3 file using OpenCV.\n",
        "\n",
        "#   Args:\n",
        "#       video_path (str): Path to the input video file.\n",
        "#       output_path (str, optional): Path to save the extracted audio file (MP3 format). Defaults to \"audio.mp3\".\n",
        "#   \"\"\"\n",
        "\n",
        "#   # Open the video capture object\n",
        "#   cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "#   # Check if video was opened successfully\n",
        "#   if not cap.isOpened():\n",
        "#     print(\"Error opening video file:\", video_path)\n",
        "#     return\n",
        "\n",
        "#   # Get audio sample rate and channels\n",
        "#   audio_fps = int(cap.get(cv2.CAP_PROP_FPS))  # Assuming audio sample rate matches video FPS\n",
        "#   audio_channels = 2  # Adjust for stereo or mono\n",
        "\n",
        "#   # Audio recording object\n",
        "#   audio_out = wave.open(output_path, 'wb')\n",
        "\n",
        "#   # Set audio recording parameters\n",
        "#   audio_out.setnchannels(audio_channels)\n",
        "#   audio_out.setsampwidth(2)  # Assuming 16-bit audio (2 bytes per sample)\n",
        "#   audio_out.setframerate(audio_fps)\n",
        "\n",
        "#   while True:\n",
        "#     # Read video frame (frame is not used here, but required by OpenCV)\n",
        "#     ret, frame = cap.read()\n",
        "\n",
        "#     if not ret:\n",
        "#       # End of video\n",
        "#       break\n",
        "\n",
        "#     # Read audio data\n",
        "#     audio_data = cap.read(1)[1]  # Assuming audio data at index 1\n",
        "\n",
        "#     # Check if audio data exists and write to file\n",
        "#     if np.any(audio_data):\n",
        "#       audio_out.writeframes(audio_data)\n",
        "\n",
        "#   # Release resources\n",
        "#   cap.release()\n",
        "#   audio_out.close()\n",
        "\n",
        "#   print(\"Audio extracted successfully!\")\n",
        "\n",
        "# # Example usage\n",
        "# video_path = \"/content/2.mp4\"\n",
        "\n",
        "# extract_audio_to_mp3(video_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZGAzDUVfAsL"
      },
      "outputs": [],
      "source": [
        "# !pip install diffusers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AWaBfG0de4Q"
      },
      "outputs": [],
      "source": [
        "# #2.2.3.1\n",
        "# import torch\n",
        "# from diffusers import StableDiffusionInstructPix2PixPipeline\n",
        "# from diffusers.utils import load_image\n",
        "\n",
        "# model_id = \"instruction-tuning-sd/cartoonizer\"\n",
        "# pipeline = StableDiffusionInstructPix2PixPipeline.from_pretrained(\n",
        "#     model_id, torch_dtype=torch.float16, use_auth_token=True\n",
        "# ).to(\"cuda\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udWZo7LDiuuE"
      },
      "outputs": [],
      "source": [
        "# image_path = \"/content/1.jpg\"\n",
        "# image = load_image(image_path)\n",
        "\n",
        "# image = pipeline(\"cartonize the image completely so that the maximum cartoon is achieved\", image=image).images[0]\n",
        "# image.save(\"imagecartoon1.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPVxe3V1jA-7"
      },
      "outputs": [],
      "source": [
        "# image_path = \"/content/1.jpg\"\n",
        "# image = load_image(image_path)\n",
        "\n",
        "# image1 = pipeline(\"Cartoonize the following image\", image=image).images[0]\n",
        "# image1.save(\"image2.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaZxxLSMpvxx",
        "outputId": "504f2c07-e32a-47fc-c3bd-ac45ad30ee5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (0.27.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (7.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.20.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.25.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.4.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (9.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.29.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "! pip install diffusers transformers accelerate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OO9M-yjSpqbI"
      },
      "outputs": [],
      "source": [
        "# # 2.2.3.2\n",
        "# import cv2\n",
        "# from PIL import Image\n",
        "# from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\n",
        "# import torch\n",
        "# import numpy as np\n",
        "# from diffusers.utils import load_image\n",
        "\n",
        "# # image = load_image(\"https://huggingface.co/lllyasviel/sd-controlnet-hed/resolve/main/images/bird.png\")\n",
        "# image_path = \"/content/1.jpg\"\n",
        "# image = load_image(image_path)\n",
        "# image = np.array(image)\n",
        "\n",
        "# low_threshold = 100\n",
        "# high_threshold = 200\n",
        "\n",
        "# image = cv2.Canny(image, low_threshold, high_threshold)\n",
        "# image = image[:, :, None]\n",
        "# image = np.concatenate([image, image, image], axis=2)\n",
        "# image = Image.fromarray(image)\n",
        "\n",
        "# controlnet = ControlNetModel.from_pretrained(\n",
        "#     \"lllyasviel/sd-controlnet-canny\", torch_dtype=torch.float16\n",
        "# )\n",
        "\n",
        "# pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
        "#     \"runwayml/stable-diffusion-v1-5\", controlnet=controlnet, safety_checker=None, torch_dtype=torch.float16\n",
        "# )\n",
        "\n",
        "# pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "# # Remove if you do not have xformers installed\n",
        "# # see https://huggingface.co/docs/diffusers/v0.13.0/en/optimization/xformers#installing-xformers\n",
        "# # for installation instructions\n",
        "# # pipe.enable_xformers_memory_efficient_attention()\n",
        "\n",
        "# pipe.enable_model_cpu_offload()\n",
        "\n",
        "# image = pipe(\"anime girl\", image, num_inference_steps=20).images[0]\n",
        "\n",
        "# image.save('content/girl_anime_out.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455,
          "referenced_widgets": [
            "cf1fce484c0a421fa42931ed02de5efc",
            "eb33ca2d541d4dcc90918284090eccf3",
            "d4f09c069fa441749c1973578c01dc2e",
            "daf1403b677d45ada45972d2b571e12d",
            "6d4813ee307c483b86aec12f93fa813b",
            "66d17a3fc54b4cb986b2a0150223445c",
            "48e929dab75c410d87bfff1f7c7c1824",
            "8851da4478154448a80b4f0fea0706d2",
            "93e1ff14a697408a9d906c9d9666d924",
            "de27bf9e66c94fc9a1fe44bd4207bab6",
            "1f0048f5453b42ceb0691039fc294454",
            "17a450dfc0394e42b2e5d4f94da9a343",
            "80d059789be649c3897880eb163915db",
            "8c35c062fbd944598bb62d69ef882622",
            "97eecbb38355477c80d21584f0143461",
            "a08999fa606049eeb3f58a6aa53a07a1",
            "a932a5b438cd4b0fb413d280d50c67ec",
            "77fe7a57c6fe4811aadca315a50c1abd",
            "f54b89f4680840688f0afc25bada35ff",
            "a0eb9bfc9b684d478e9701c6124785bd",
            "9492c9defd3048b9819deca48e2d38d8",
            "74afb933c0ca4b329f7cf0e9bc0ebf93"
          ]
        },
        "id": "GuFmq_xWmNIO",
        "outputId": "867d54d6-843c-4371-e5c1-9787a84d5572"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf1fce484c0a421fa42931ed02de5efc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17a450dfc0394e42b2e5d4f94da9a343",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-33392f60074f>\u001b[0m in \u001b[0;36m<cell line: 47>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mimage_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"extracted_images\"\u001b[0m  \u001b[0;31m# Replace with your image directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0medit_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-33392f60074f>\u001b[0m in \u001b[0;36medit_images\u001b[0;34m(image_dir)\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0;31m# image_path = \"/content/extracted_images/image_00999.png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0;31m# image = load_image(image_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m       \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cartoonize the following image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m       \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_instruct_pix2pix.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, prompt, image, num_inference_steps, guidance_scale, image_guidance_scale, negative_prompt, num_images_per_prompt, eta, generator, latents, prompt_embeds, negative_prompt_embeds, ip_adapter_image, output_type, return_dict, callback_on_step_end, callback_on_step_end_tensor_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;31m# predict the noise residual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m                 noise_pred = self.unet(\n\u001b[0m\u001b[1;32m    405\u001b[0m                     \u001b[0mscaled_latent_model_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/models/unets/unet_2d_condition.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sample, timestep, encoder_hidden_states, class_labels, timestep_cond, attention_mask, cross_attention_kwargs, added_cond_kwargs, down_block_additional_residuals, mid_block_additional_residual, down_intrablock_additional_residuals, encoder_attention_mask, return_dict)\u001b[0m\n\u001b[1;32m   1244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmid_block\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmid_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"has_cross_attention\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmid_block\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_cross_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1246\u001b[0;31m                 sample = self.mid_block(\n\u001b[0m\u001b[1;32m   1247\u001b[0m                     \u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m                     \u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/models/unets/unet_2d_blocks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, temb, encoder_hidden_states, attention_mask, cross_attention_kwargs, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Passing `scale` to `cross_attention_kwargs` is depcrecated. `scale` will be ignored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattentions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_checkpointing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, temb, *args, **kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonlinearity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         return F.group_norm(\n\u001b[0m\u001b[1;32m    288\u001b[0m             input, self.num_groups, self.weight, self.bias, self.eps)\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mgroup_norm\u001b[0;34m(input, num_groups, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2559\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Expected at least 2 dimensions for input tensor but received {input.dim()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2560\u001b[0m     \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mnum_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_groups\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2561\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#2.2.1\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def edit_images(image_dir):\n",
        "  \"\"\"Edits images in a directory (replace with your desired edits).\n",
        "\n",
        "  Args:\n",
        "      image_dir (str): Path to the directory containing images.\n",
        "  \"\"\"\n",
        "  indexingfor = 0\n",
        "  for filename in os.listdir(image_dir):\n",
        "    if filename.endswith(\".png\") or filename.endswith(\".jpg\"):  # Adjust extensions\n",
        "      image_path = os.path.join(image_dir, filename)\n",
        "\n",
        "      image = cv2.imread(image_path)\n",
        "\n",
        "      # Convert to grayscale (replace with your edits)\n",
        "      # grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "      preprocessed_image = preprocess_image(image)\n",
        "\n",
        "      # Run inference.\n",
        "      result = concrete_func(preprocessed_image)[\"final_output:0\"]\n",
        "\n",
        "      # Post-process the result and serialize it.\n",
        "      output = (result[0].numpy() + 1.0) * 127.5\n",
        "      output = np.clip(output, 0, 255).astype(np.uint8)\n",
        "      output = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)\n",
        "      output_image = Image.fromarray(output)\n",
        "      output_image.save(image_path)\n",
        "\n",
        "\n",
        "      # # image_path = \"/content/extracted_images/image_00999.png\"\n",
        "      # # image = load_image(image_path)\n",
        "      # image = pipeline(\"Cartoonize the following image\", image=image).images[0]\n",
        "      # image.save(image_path)\n",
        "\n",
        "\n",
        "      # Save the edited image\n",
        "      # cv2.imwrite(image_path,  grayscale_image)\n",
        "      indexingfor += 1\n",
        "      if indexingfor  % 50 == 0:\n",
        "        print(indexingfor)\n",
        "# Example usage\n",
        "image_dir = \"extracted_images\"  # Replace with your image directory\n",
        "\n",
        "edit_images(image_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxCaZvujOSYw"
      },
      "outputs": [],
      "source": [
        "# # 2.2.2.1\n",
        "# import torch\n",
        "# from diffusers import DiffusionPipeline\n",
        "\n",
        "# # Text to Multi-View Diffusion\n",
        "# text_pipeline = DiffusionPipeline.from_pretrained(\n",
        "#     \"ashawkey/mvdream-sd2.1-diffusers\",\n",
        "#     custom_pipeline=\"dylanebert/multi_view_diffusion\",\n",
        "#     torch_dtype=torch.float16,\n",
        "#     trust_remote_code=True,\n",
        "# ).to(\"cuda\")\n",
        "\n",
        "# # Image to Multi-View Diffusion\n",
        "# image_pipeline = DiffusionPipeline.from_pretrained(\n",
        "#     \"ashawkey/imagedream-ipmv-diffusers\",\n",
        "#     custom_pipeline=\"dylanebert/multi_view_diffusion\",\n",
        "#     torch_dtype=torch.float16,\n",
        "#     trust_remote_code=True,\n",
        "# ).to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9Z5W6OQPmNP"
      },
      "outputs": [],
      "source": [
        "# !pip install diffusers\n",
        "# !pip install accelerate einops xformers kiui"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rxdIMLGPgC-"
      },
      "outputs": [],
      "source": [
        "# # 2.2.2.2\n",
        "# # Imports\n",
        "# import cv2\n",
        "# from diffusers import DiffusionPipeline\n",
        "# import torch\n",
        "# import numpy as np\n",
        "# # Model loading (assuming pre-downloaded models)\n",
        "# text_pipeline = DiffusionPipeline.from_pretrained(\n",
        "#     \"ashawkey/mvdream-sd2.1-diffusers\",\n",
        "#     custom_pipeline=\"dylanebert/multi_view_diffusion\",\n",
        "#     torch_dtype=torch.float16,\n",
        "#     trust_remote_code=True,\n",
        "# ).to(\"cuda\")\n",
        "\n",
        "# image_pipeline = DiffusionPipeline.from_pretrained(\n",
        "#     \"ashawkey/imagedream-ipmv-diffusers\",\n",
        "#     custom_pipeline=\"dylanebert/multi_view_diffusion\",\n",
        "#     torch_dtype=torch.float16,\n",
        "#     trust_remote_code=True,\n",
        "# ).to(\"cuda\")\n",
        "\n",
        "# # Load your image (replace with your path)\n",
        "# image = cv2.imread(\"/content/1 (1).jpeg\")\n",
        "# image = image.astype(np.float32)\n",
        "\n",
        "# # Preprocess the image (resize, convert to RGB, etc.)\n",
        "# # ... (Your image preprocessing logic here)\n",
        "# if image.dtype != torch.float32:\n",
        "#   image = torch.from_numpy(image).float()\n",
        "# # Define your text prompt for modification\n",
        "# prompt = \"The image with a more vibrant color scheme\"  # Example prompt\n",
        "\n",
        "# # Generate the modified image\n",
        "# generated_image = image_pipeline(\n",
        "#     image=image,\n",
        "#     prompt=prompt,\n",
        "#     guidance_scale=7.5,  # Adjust guidance scale for stronger/weaker modifications (default 7.5)\n",
        "# )[\"images\"][0]\n",
        "\n",
        "# # Save or display the generated image\n",
        "# cv2.imwrite(\"modified_image.jpg\", generated_image)\n",
        "\n",
        "# # Or display the generated image\n",
        "# cv2.imshow(\"Modified Image\", generated_image)\n",
        "# cv2.waitKey(0)\n",
        "# cv2.destroyAllWindows()\n",
        "\n",
        "# print(\"Image modification complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLnsxpDUmfbo"
      },
      "outputs": [],
      "source": [
        "# import cv2\n",
        "# import os\n",
        "\n",
        "# def create_video(image_dir, output_video_path, target_fps=30):\n",
        "#   \"\"\"Creates a video from a directory of images at the specified target frame rate.\n",
        "\n",
        "#   Args:\n",
        "#       image_dir (str): Path to the directory containing images.\n",
        "#       output_video_path (str): Path to the output video file.\n",
        "#       target_fps (int, optional): Target frame rate for the output video. Defaults to 30.\n",
        "#   \"\"\"\n",
        "\n",
        "#   # Get the first image to determine frame size\n",
        "#   images = [f for f in os.listdir(image_dir) if f.endswith(\".png\") or f.endswith(\".jpg\")]  # Adjust extensions for your image format\n",
        "#   image_path = os.path.join(image_dir, images[0])\n",
        "#   image = cv2.imread(image_path)\n",
        "#   height, width, _ = image.shape\n",
        "\n",
        "#   # Create video writer with appropriate codec (adjust if needed)\n",
        "#   fourcc = cv2.VideoWriter_fourcc(*'XVID')  # 'XVID' is a common codec, adjust based on your needs\n",
        "#   video_writer = cv2.VideoWriter(output_video_path, fourcc, target_fps, (width, height))\n",
        "\n",
        "#   # Add each image to the video writer\n",
        "#   for filename in images:\n",
        "#     image_path = os.path.join(image_dir, filename)\n",
        "#     image = cv2.imread(image_path)\n",
        "#     video_writer.write(image)\n",
        "\n",
        "#   # Release the video writer\n",
        "#   video_writer.release()\n",
        "#   print(\"Video created successfully!\")\n",
        "\n",
        "# # Example usage\n",
        "# image_dir = \"extracted_images\"  # Replace with your image directory\n",
        "# output_video_path = \"edited_video.mp4\"  # Replace with your desired output video path\n",
        "\n",
        "# create_video(image_dir, output_video_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tj3j75_ssAgu",
        "outputId": "77ed3a27-49dc-4df7-f8ad-1de694c80de2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video created successfully!\n"
          ]
        }
      ],
      "source": [
        "#3.1\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def create_video(image_dir, output_video_path, target_fps=30, max_duplicates=1):\n",
        "  \"\"\"Creates a video from a directory of images at the specified target frame rate,\n",
        "  reducing repeated frames and improving video quality.\n",
        "\n",
        "  Args:\n",
        "      image_dir (str): Path to the directory containing images.\n",
        "      output_video_path (str): Path to the output video file.\n",
        "      target_fps (int, optional): Target frame rate for the output video. Defaults to 30.\n",
        "      max_duplicates (int, optional): Maximum number of times a consecutive image can be repeated. Defaults to 1 (no duplicates).\n",
        "  \"\"\"\n",
        "\n",
        "  # Track previously seen filenames and their counts\n",
        "  seen_filenames = {}\n",
        "\n",
        "  # Get the first image to determine frame size\n",
        "  images = sorted([f for f in os.listdir(image_dir) if f.endswith(\".png\") or f.endswith(\".jpg\")])  # Sort images (optional)\n",
        "  image_path = os.path.join(image_dir, images[0])\n",
        "  image = cv2.imread(image_path)\n",
        "  height, width, _ = image.shape\n",
        "\n",
        "  # Create video writer with appropriate codec (adjust if needed)\n",
        "  fourcc = cv2.VideoWriter_fourcc(*'XVID')  # 'XVID' is a common codec, adjust based on your needs\n",
        "  video_writer = cv2.VideoWriter(output_video_path, fourcc, target_fps, (width, height))\n",
        "\n",
        "  # Add each image, considering duplicates\n",
        "  for filename in images:\n",
        "    image_path = os.path.join(image_dir, filename)\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Check if image has been seen before and limit consecutive duplicates\n",
        "    if filename in seen_filenames and seen_filenames[filename] >= max_duplicates:\n",
        "      continue\n",
        "    else:\n",
        "      seen_filenames[filename] = seen_filenames.get(filename, 0) + 1\n",
        "\n",
        "    video_writer.write(image)\n",
        "\n",
        "  # Release the video writer\n",
        "  video_writer.release()\n",
        "  print(\"Video created successfully!\")\n",
        "\n",
        "# Example usage\n",
        "image_dir = \"extracted_images\"  # Replace with your image directory\n",
        "output_video_path = \"/content/Gangs of Godavari - Teaser  Vishwak Sen  Krishna Chaitanya  Yuvan Shankar Raja  S Naga Vamsi EDITED.mp4\"  # Replace with your desired output video path\n",
        "max_duplicates = 2  # Adjust the maximum number of consecutive duplicates allowed\n",
        "\n",
        "create_video(image_dir, output_video_path, target_fps=30, max_duplicates=max_duplicates)  # Adjust target FPS as needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nNBkSCi0u_n"
      },
      "outputs": [],
      "source": [
        "# #3.2\n",
        "# import cv2\n",
        "\n",
        "# def get_video_info(video_path):\n",
        "#   \"\"\"Gets the length (duration) and number of frames in a video using OpenCV.\n",
        "\n",
        "#   Args:\n",
        "#       video_path (str): Path to the video file.\n",
        "\n",
        "#   Returns:\n",
        "#       tuple: A tuple containing video length (in seconds) and number of frames (int).\n",
        "#   \"\"\"\n",
        "\n",
        "#   # Open the video capture object\n",
        "#   cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "#   # Check if video was opened successfully\n",
        "#   if not cap.isOpened():\n",
        "#     print(\"Error opening video file:\", video_path)\n",
        "#     return None, None\n",
        "\n",
        "#   # Get video properties\n",
        "#   fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "#   frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "#   # Calculate video length (duration) in seconds\n",
        "#   video_length = frame_count / fps\n",
        "\n",
        "#   # Release resources\n",
        "#   cap.release()\n",
        "\n",
        "#   return video_length, frame_count\n",
        "\n",
        "# # Example usage\n",
        "# video_path = \"/content/edited_video.mp4\"\n",
        "\n",
        "# video_length, frame_count = get_video_info(video_path)\n",
        "\n",
        "# if video_length is not None and frame_count is not None:\n",
        "#   print(\"Video length:\", video_length, \"seconds\")\n",
        "#   print(\"Number of frames:\", frame_count)\n",
        "# frpersec = frame_count/ video_length\n",
        "# print(frpersec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEaC-dq6zLDD"
      },
      "outputs": [],
      "source": [
        "# #3.3\n",
        "# import cv2\n",
        "\n",
        "# def speed_up_video(video_path, output_path, speed_factor=2):\n",
        "#   \"\"\"Speeds up a video by the specified factor using frame skipping.\n",
        "\n",
        "#   Args:\n",
        "#       video_path (str): Path to the input video file.\n",
        "#       output_path (str): Path to save the sped-up video file.\n",
        "#       speed_factor (float, optional): Speed factor to apply. Defaults to 2 (twice the speed).\n",
        "#   \"\"\"\n",
        "\n",
        "#   # Open the video capture object\n",
        "#   cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "#   # Check if video was opened successfully\n",
        "#   if not cap.isOpened():\n",
        "#     print(\"Error opening video file:\", video_path)\n",
        "#     return\n",
        "\n",
        "#   # Get video properties (assuming constant frame rate)\n",
        "#   frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "#   frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "#   original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "#   new_fps = int(original_fps * speed_factor)\n",
        "\n",
        "#   # Create video writer for output\n",
        "#   fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Adjust codec as needed (e.g., 'MP4V' for mp4)\n",
        "#   out = cv2.VideoWriter(output_path, fourcc, new_fps, (frame_width, frame_height))\n",
        "\n",
        "#   # Skip frames based on speed factor\n",
        "#   frame_count = 0\n",
        "#   while True:\n",
        "#     # Capture frame-by-frame\n",
        "#     ret, frame = cap.read()\n",
        "\n",
        "#     if not ret:\n",
        "#       # End of video\n",
        "#       break\n",
        "\n",
        "#     # Skip frames based on speed factor (consider rounding for smoother playback)\n",
        "#     if frame_count % int(round(speed_factor)) == 0:\n",
        "#       out.write(frame)\n",
        "\n",
        "#     frame_count += 1\n",
        "\n",
        "#   # Release resources\n",
        "#   cap.release()\n",
        "#   out.release()\n",
        "\n",
        "#   print(\"Video sped up successfully!\")\n",
        "\n",
        "# # Example usage\n",
        "# video_path = \"/content/edited_video.mp4\"\n",
        "# output_path = \"sped_up_video.mp4\"\n",
        "# speed_factor = 1.5  # Adjust speed factor (higher value means faster video)\n",
        "\n",
        "# speed_up_video(video_path, output_path, speed_factor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxNWAMSeCtbP"
      },
      "outputs": [],
      "source": [
        "# # 3.4\n",
        "# from moviepy.editor import VideoFileClip, AudioFileClip\n",
        "\n",
        "# def join_audio_video(video_path, audio_path, output_path=\"output.mp4\"):\n",
        "#   \"\"\"Joins an audio file with a video and saves the combined result.\n",
        "\n",
        "#   Args:\n",
        "#       video_path (str): Path to the input video file (.mp4).\n",
        "#       audio_path (str): Path to the input audio file.\n",
        "#       output_path (str, optional): Path to save the combined video file. Defaults to \"output.mp4\".\n",
        "#   \"\"\"\n",
        "\n",
        "#   # Create video and audio clip objects\n",
        "#   video_clip = VideoFileClip(video_path)\n",
        "#   audio_clip = AudioFileClip(audio_path)\n",
        "\n",
        "#   # Ensure audio duration matches or is longer than video\n",
        "#   if audio_clip.duration < video_clip.duration:\n",
        "#     print(\"Warning: Audio is shorter than video. Padding silence to match video duration.\")\n",
        "#     # Extend audio with silence to match video duration (adjust silence duration as needed)\n",
        "#     silence = AudioFileClip.silent(video_clip.duration - audio_clip.duration)\n",
        "#     audio_clip = audio_clip.set_duration(video_clip.duration).concatenate(silence)\n",
        "\n",
        "#   # Set video's audio to None to avoid duplicate audio tracks\n",
        "#   video_clip = video_clip.set_audio(None)\n",
        "\n",
        "#   # Combine video and audio clips\n",
        "#   final_clip = video_clip.set_audio(audio_clip)\n",
        "\n",
        "#   # Write the combined video to a file\n",
        "#   final_clip.write_videofile(output_path)\n",
        "\n",
        "#   print(\"Video and audio joined successfully!\")\n",
        "\n",
        "# # Example usage with moviepy installed (assuming pip install moviepy.editor is done)\n",
        "# video_path = \"/content/edited_video.mp4\"\n",
        "# audio_path = \"/content/output.wav\"  # Adjust audio file format as needed\n",
        "# output_path=\"output.mp4\"\n",
        "# join_audio_video(video_path, audio_path,output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NE-miX48DkUj"
      },
      "outputs": [],
      "source": [
        "# from moviepy.editor import VideoFileClip, AudioFileClip\n",
        "\n",
        "# def join_audio_video_fast(video_path, audio_path, output_path=\"output.mp4\"):\n",
        "#   \"\"\"Joins a WAV audio file with a video (.mp4) using moviepy.editor.\n",
        "\n",
        "#   Args:\n",
        "#       video_path (str): Path to the input video file (.mp4).\n",
        "#       audio_path (str): Path to the input audio file (WAV format).\n",
        "#       output_path (str, optional): Path to save the combined video file. Defaults to \"output.mp4\".\n",
        "#   \"\"\"\n",
        "\n",
        "#   # Create video and audio clip objects\n",
        "#   video_clip = VideoFileClip(video_path)\n",
        "#   audio_clip = AudioFileClip(audio_path)\n",
        "\n",
        "#   # Ensure audio duration matches or is longer than video\n",
        "#   if audio_clip.duration < video_clip.duration:\n",
        "#     print(\"Warning: Audio is shorter than video. Padding silence to match video duration.\")\n",
        "#     # Extend audio with silence to match video duration (adjust silence duration as needed)\n",
        "#     silence = AudioFileClip.silent(video_clip.duration - audio_clip.duration)\n",
        "#     audio_clip = audio_clip.set_duration(video_clip.duration).concatenate(silence)\n",
        "\n",
        "#   # Set video's audio to None to avoid duplicate audio tracks\n",
        "#   video_clip = video_clip.set_audio(None)\n",
        "\n",
        "#   # Combine video and audio clips\n",
        "#   final_clip = video_clip.set_audio(audio_clip)\n",
        "\n",
        "#   # Write the combined video to a file\n",
        "#   final_clip.write_videofile(output_path)\n",
        "\n",
        "#   print(\"Video and audio joined successfully!\")\n",
        "\n",
        "# video_path = \"/content/edited_video.mp4\"\n",
        "# audio_path = \"/content/output.wav\"  # Adjust audio file format as needed\n",
        "# output_path=\"output.mp4\"\n",
        "# join_audio_video(video_path, audio_path,output_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "fGxM1nNBEXfv",
        "outputId": "70f6d59d-bb81-40cb-9a48-2247a3ba28be"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'video_fps'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-bbba54eb24ec>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0maudio_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"extracted_audio.mp3\"\u001b[0m  \u001b[0;31m# Path to the extracted audio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/Gangs of Godavari - Teaser  Vishwak Sen  Krishna Chaitanya  Yuvan Shankar Raja  S Naga Vamsi combined_video.mp4\"\u001b[0m  \u001b[0;31m# Adjust the output path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mjoin_video_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-bbba54eb24ec>\u001b[0m in \u001b[0;36mjoin_video_audio\u001b[0;34m(video_path, audio_path, output_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m   \"\"\"\n\u001b[1;32m     12\u001b[0m   \u001b[0mvideo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0mfinal_video\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mfinal_video\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_videofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/moviepy/video/io/VideoFileClip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, has_mask, audio, audio_buffersize, target_resolution, resize_algorithm, audio_fps, audio_nbytes, verbose, fps_source)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m# Make a reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mpix_fmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"rgba\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhas_mask\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"rgb24\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         self.reader = FFMPEG_VideoReader(filename, pix_fmt=pix_fmt,\n\u001b[0m\u001b[1;32m     89\u001b[0m                                          \u001b[0mtarget_resolution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_resolution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                                          \u001b[0mresize_algo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresize_algorithm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, print_infos, bufsize, pix_fmt, check_duration, target_resolution, resize_algo, fps_source)\u001b[0m\n\u001b[1;32m     35\u001b[0m         infos = ffmpeg_parse_infos(filename, print_infos, check_duration,\n\u001b[1;32m     36\u001b[0m                                    fps_source)\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'video_fps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'video_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'video_rotation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'video_fps'"
          ]
        }
      ],
      "source": [
        "# 3.5.1.1\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "def join_video_audio(video_path, audio_path, output_path):\n",
        "  \"\"\"Joins a video with a separate audio track and saves the combined video.\n",
        "\n",
        "  Args:\n",
        "      video_path: Path to the video file.\n",
        "      audio_path: Path to the audio file (MP3 format) to be added.\n",
        "      output_path: Path to save the combined video file.\n",
        "  \"\"\"\n",
        "  video = VideoFileClip(video_path)\n",
        "  audio = VideoFileClip(audio_path)\n",
        "  final_video = video.set_audio(audio)\n",
        "  final_video.write_videofile(output_path)\n",
        "  print(f\"Video and audio joined and saved to: {output_path}\")\n",
        "\n",
        "# Example usage\n",
        "video_path = \"/content/Gangs of Godavari - Teaser  Vishwak Sen  Krishna Chaitanya  Yuvan Shankar Raja  S Naga Vamsi EDITED.mp4\"  # Replace with your video path\n",
        "audio_path = \"extracted_audio.mp3\"  # Path to the extracted audio\n",
        "output_path = \"/content/Gangs of Godavari - Teaser  Vishwak Sen  Krishna Chaitanya  Yuvan Shankar Raja  S Naga Vamsi combined_video.mp4\"  # Adjust the output path\n",
        "join_video_audio(video_path, audio_path, output_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kImruqje76pe",
        "outputId": "8f0fe903-fb3f-48b3-905f-1d289a02302b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "\u001b[1;31m/content/Gangs: No such file or directory\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# 3.5.1.2\n",
        "!ffmpeg -i {video_path} -i {audio_path} -c copy {output_path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dD1csUCJ8lrQ",
        "outputId": "18014c34-d858-40f8-dafc-162969abe6eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video and audio combined and saved to: /content/Gangs of Godavari - Teaser  Vishwak Sen  Krishna Chaitanya  Yuvan Shankar Raja  S Naga Vamsi combined_video.mp4\n"
          ]
        }
      ],
      "source": [
        "# 3.5.1.3\n",
        "import cv2\n",
        "\n",
        "def combine_video_audio(video_path, audio_path, output_path):\n",
        "  \"\"\"Combines a video with an MP3 song and saves the result.\n",
        "\n",
        "  Args:\n",
        "      video_path: Path to the video file.\n",
        "      audio_path: Path to the MP3 song file.\n",
        "      output_path: Path to save the combined video file.\n",
        "\n",
        "  Raises:\n",
        "      ValueError: If video or audio cannot be opened.\n",
        "  \"\"\"\n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "  if not cap.isOpened():\n",
        "    raise ValueError(\"Error opening video file\")\n",
        "\n",
        "  fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "  width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "  height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "  # Open audio using an external library (e.g., pyaudio, playsound)\n",
        "  # This example uses a placeholder audio opening function\n",
        "  audio = open_audio(audio_path)\n",
        "\n",
        "  # Combine video and audio using external libraries (e.g., moviepy)\n",
        "  # This example skips combining as cv2 doesn't natively handle audio\n",
        "  # You'll need to implement audio synchronization and mixing using other libraries\n",
        "\n",
        "  fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Adjust codec if needed\n",
        "  out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "  while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "      break\n",
        "    out.write(frame)\n",
        "\n",
        "  cap.release()\n",
        "  out.release()\n",
        "  # Close audio using the external library's method (placeholder here)\n",
        "  close_audio(audio)\n",
        "\n",
        "  print(f\"Video and audio combined and saved to: {output_path}\")\n",
        "\n",
        "# Placeholder functions for audio (replace with actual implementations)\n",
        "def open_audio(audio_path):\n",
        "  # Implement audio opening using a suitable library (e.g., pyaudio, playsound)\n",
        "  # This function should return an audio object or handle opening logic\n",
        "  pass\n",
        "\n",
        "def close_audio(audio):\n",
        "  # Implement audio closing using the library's method (placeholder here)\n",
        "  pass\n",
        "\n",
        "# Example usage\n",
        "video_path = \"/content/Gangs of Godavari - Teaser  Vishwak Sen  Krishna Chaitanya  Yuvan Shankar Raja  S Naga Vamsi.mp4\"  # Replace with your video path\n",
        "audio_path = \"extracted_audio.mp3\"  # Path to the extracted audio\n",
        "output_path = \"/content/Gangs of Godavari - Teaser  Vishwak Sen  Krishna Chaitanya  Yuvan Shankar Raja  S Naga Vamsi combined_video.mp4\"  # Adjust the output path\n",
        "\n",
        "\n",
        "try:\n",
        "  combine_video_audio(video_path, audio_path, output_path)\n",
        "except ValueError as e:\n",
        "  print(f\"Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yayh-G8w9ykB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5592OS5guuEf"
      },
      "source": [
        "# audio to text generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8-gqzSUvU9z",
        "outputId": "e7679696-15b0-4608-d7b2-26d256cd084d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diffusers\n",
            "  Downloading diffusers-0.27.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (7.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (9.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, diffusers, accelerate\n",
            "Successfully installed accelerate-0.29.3 diffusers-0.27.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers accelerate diffusers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "lWTgkyoCuzE7",
        "outputId": "a3593b49-ee3f-4e26-9315-f822bd593adf"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-45cecda62fe8>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"openai/whisper-large-v3\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m model = AutoModelForSpeechSeq2Seq.from_pretrained(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_cpu_mem_usage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_safetensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    564\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3084\u001b[0m                 )\n\u001b[1;32m   3085\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_accelerate_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3086\u001b[0;31m                 raise ImportError(\n\u001b[0m\u001b[1;32m   3087\u001b[0m                     \u001b[0;34m\"Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3088\u001b[0m                 )\n",
            "\u001b[0;31mImportError\u001b[0m: Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
        "# from datasets import load_dataset\n",
        "\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "\n",
        "model_id = \"openai/whisper-large-v3\"\n",
        "\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=model,\n",
        "    tokenizer=processor.tokenizer,\n",
        "    feature_extractor=processor.feature_extractor,\n",
        "    max_new_tokens=128,\n",
        "    chunk_length_s=30,\n",
        "    batch_size=16,\n",
        "    return_timestamps=True,\n",
        "    torch_dtype=torch_dtype,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "# dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\n",
        "# sample = dataset[0][\"audio\"]\n",
        "sample = \"/content/extracted_audio.mp3\"\n",
        "result = pipe(sample)\n",
        "print(result[\"text\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0m5H-aQvKyC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09ea73a133e84659aa1bdb89f9e06be2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d971e89d4af4924b16d8fefd7763506": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73c1c3ca5a514a4b872ec0cada1a837b",
            "max": 2176062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0ef27fa4ecb491aa44deb9c3a0ea29b",
            "value": 2176062
          }
        },
        "0f9fe2c24c56479bb7f23d557114f5e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e540d93d806f4ef4917d8212ffb59f09",
              "IPY_MODEL_5563fafa006f4f1a95b2d8cab2e83131",
              "IPY_MODEL_bac2b959dd48467999e4de0a35e40f46"
            ],
            "layout": "IPY_MODEL_485d637bb10a40a6b036bb92216d6e02"
          }
        },
        "10526fa1368444e38cc56193d93b4d89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c244c90a1de42f6b108979bac5d6951",
            "max": 2350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e50248c836e54fa7b2ba108555b63afe",
            "value": 2350
          }
        },
        "10dfddd8aeb447b9a728819f19f19db6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1353f0ea70ed47949a8b261713b7495c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "138f95e24b3440de8c24729862953298": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_801c12b0a6ab4e138522e3de45f659e2",
            "placeholder": "",
            "style": "IPY_MODEL_466802cd5bed4a0daaed6386c4f1892d",
            "value": ".gitattributes:100%"
          }
        },
        "17a450dfc0394e42b2e5d4f94da9a343": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80d059789be649c3897880eb163915db",
              "IPY_MODEL_8c35c062fbd944598bb62d69ef882622",
              "IPY_MODEL_97eecbb38355477c80d21584f0143461"
            ],
            "layout": "IPY_MODEL_a08999fa606049eeb3f58a6aa53a07a1"
          }
        },
        "18da201f07e44ba69ac5f234ed431d52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e6ccaec1f80421389b87c78673043a4",
            "placeholder": "",
            "style": "IPY_MODEL_d00f9b5d11644039b239e870f0db164f",
            "value": "saved_model.pb:100%"
          }
        },
        "1ec8385fae664d8fb94e292d4e78e1cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_138f95e24b3440de8c24729862953298",
              "IPY_MODEL_e0c80050023f466bac0c8e9b371f0b5b",
              "IPY_MODEL_697ed0d812e44b0a85c7dcd8ab4b09fb"
            ],
            "layout": "IPY_MODEL_f40c037a4388487a91600a9250c8d2b8"
          }
        },
        "1f0048f5453b42ceb0691039fc294454": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f07c99bc3e24846b65d2060ffa1bf44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2343eed89b2d4410ab729d5d3610bc6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "235010e5be824fc78c437798919b7aff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2797dfe6a61b4a209930fc6f2413211f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a3373a99c7f4f54bbfba15e73f27935",
              "IPY_MODEL_2cce0fe43b624a518883be8eed8f34c8",
              "IPY_MODEL_6a32d7a3770244dd8770f5874434c5b2"
            ],
            "layout": "IPY_MODEL_f7d4002dc5474b248fc7b7177081d2e2"
          }
        },
        "2bf3e7e5d41d4ee6a06eb7a85c6970ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cce0fe43b624a518883be8eed8f34c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78f25e7802e14051b967f37193dab465",
            "max": 1561,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f029ea9cfb5b4330af25157968b0084d",
            "value": 1561
          }
        },
        "2d1ca86022ea45bb8755e955fd66f95f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30c1561e707d4d8286ca6a643e54590f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9204b71e33df4dc9980b5a1a11f5720f",
              "IPY_MODEL_a9d0a251d3bb4f60bc80d0100da51bea",
              "IPY_MODEL_be724d16178040068ef23f6de6dbdd95"
            ],
            "layout": "IPY_MODEL_6801f06aa0d2467cb31b93f961eb9a5a"
          }
        },
        "30c97ef9e70542219966f139617911e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3791e7d6dd3f4fe6829b6db0a3087410": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b118740a4d14c1eaeb5569153497a28",
            "placeholder": "",
            "style": "IPY_MODEL_735a535de3ec4c4e91f241d7d72fcac0",
            "value": "2.35k/2.35k[00:00&lt;00:00,59.7kB/s]"
          }
        },
        "392eceb2f8004931a08834b8adf99d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c858ae4afc0c4e7292f951cf5894e288",
              "IPY_MODEL_10526fa1368444e38cc56193d93b4d89",
              "IPY_MODEL_3791e7d6dd3f4fe6829b6db0a3087410"
            ],
            "layout": "IPY_MODEL_b8dac3a2723f4b48b1e2a42fb80af21a"
          }
        },
        "3c880954be7b4fbe80690722a0d925a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42143cd120134cc3974f2756c58ece42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "466802cd5bed4a0daaed6386c4f1892d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "485d637bb10a40a6b036bb92216d6e02": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48e929dab75c410d87bfff1f7c7c1824": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e6ccaec1f80421389b87c78673043a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53bb48c0c1c040f78952201729e9ce16": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5563fafa006f4f1a95b2d8cab2e83131": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5b290bdc453402899b0ff584d4e0102",
            "max": 5868300,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a9d2f163d1e49149fb02decc9c6db51",
            "value": 5868300
          }
        },
        "59f9c21439d1429aa378618eacf3b3cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_623ad51220a941efbef63ee3ac7ac13e",
              "IPY_MODEL_0d971e89d4af4924b16d8fefd7763506",
              "IPY_MODEL_9dbe518d3ff146b18b4ad76aa1d3cea2"
            ],
            "layout": "IPY_MODEL_10dfddd8aeb447b9a728819f19f19db6"
          }
        },
        "5eb4b2df28984870baa386fe4851f2aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "623ad51220a941efbef63ee3ac7ac13e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92080f9d7d944b50968d9bb7f0ffd62a",
            "placeholder": "",
            "style": "IPY_MODEL_c26be6e5f4eb4839b0c0da2d252b43ce",
            "value": "output.png:100%"
          }
        },
        "66d17a3fc54b4cb986b2a0150223445c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6801f06aa0d2467cb31b93f961eb9a5a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "680fc3a1e76a4b7a980b877c35b1fad4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "697ed0d812e44b0a85c7dcd8ab4b09fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2bf5b63b0504d65b448359e48335134",
            "placeholder": "",
            "style": "IPY_MODEL_94accabc37f642d493e14d76d018a86d",
            "value": "1.60k/1.60k[00:00&lt;00:00,95.4kB/s]"
          }
        },
        "6a050c27907647d7957c08f4622b3239": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a32d7a3770244dd8770f5874434c5b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7554b6ffc5394e6bab1a8805f6f92b6b",
            "placeholder": "",
            "style": "IPY_MODEL_ced77bb7976747e18b76530bcaa4d6c6",
            "value": "1.56k/1.56k[00:00&lt;00:00,31.6kB/s]"
          }
        },
        "6a9d2f163d1e49149fb02decc9c6db51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d4813ee307c483b86aec12f93fa813b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7150b1a4491a49ffb76a9c51788c1e11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "735a535de3ec4c4e91f241d7d72fcac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73c1c3ca5a514a4b872ec0cada1a837b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73d5f6b599dc4356afe0db3fd370ed73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74afb933c0ca4b329f7cf0e9bc0ebf93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7554b6ffc5394e6bab1a8805f6f92b6b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77fe7a57c6fe4811aadca315a50c1abd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78f25e7802e14051b967f37193dab465": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "801c12b0a6ab4e138522e3de45f659e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80d059789be649c3897880eb163915db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a932a5b438cd4b0fb413d280d50c67ec",
            "placeholder": "",
            "style": "IPY_MODEL_77fe7a57c6fe4811aadca315a50c1abd",
            "value": "7%"
          }
        },
        "811de8da95334fc480e6534fd81658e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c880954be7b4fbe80690722a0d925a4",
            "placeholder": "",
            "style": "IPY_MODEL_2bf3e7e5d41d4ee6a06eb7a85c6970ff",
            "value": "export-saved-model.ipynb:100%"
          }
        },
        "8631ea8151d34fe1b478a7aa9665c2f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8851da4478154448a80b4f0fea0706d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88b4856bbd594e88a6bfe283d43e39fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42143cd120134cc3974f2756c58ece42",
            "placeholder": "",
            "style": "IPY_MODEL_8d158654702141aca827157557af3eaa",
            "value": "146k/146k[00:00&lt;00:00,6.64MB/s]"
          }
        },
        "8b2c7c1e656c47b48501883d06cf3a40": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c35c062fbd944598bb62d69ef882622": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f54b89f4680840688f0afc25bada35ff",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0eb9bfc9b684d478e9701c6124785bd",
            "value": 7
          }
        },
        "8d158654702141aca827157557af3eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e1463f4a7074b3ca56b435e9e29d4f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9204b71e33df4dc9980b5a1a11f5720f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2c79bbdbbeb4424a105c7599bead272",
            "placeholder": "",
            "style": "IPY_MODEL_c923ee2a94fb47018262a160e8451ec9",
            "value": "Fetching7files:100%"
          }
        },
        "92080f9d7d944b50968d9bb7f0ffd62a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93e1ff14a697408a9d906c9d9666d924": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9492c9defd3048b9819deca48e2d38d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94accabc37f642d493e14d76d018a86d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97eecbb38355477c80d21584f0143461": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9492c9defd3048b9819deca48e2d38d8",
            "placeholder": "",
            "style": "IPY_MODEL_74afb933c0ca4b329f7cf0e9bc0ebf93",
            "value": "7/100[00:08&lt;01:50,1.19s/it]"
          }
        },
        "9a3373a99c7f4f54bbfba15e73f27935": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7ffb1e648cc40d78b3685f451115841",
            "placeholder": "",
            "style": "IPY_MODEL_73d5f6b599dc4356afe0db3fd370ed73",
            "value": "variables/variables.index:100%"
          }
        },
        "9b118740a4d14c1eaeb5569153497a28": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c244c90a1de42f6b108979bac5d6951": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ce54d6bc5b94bf0b1451ba29a68a031": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_811de8da95334fc480e6534fd81658e5",
              "IPY_MODEL_fb0d852a0170492d9bb49f891bb05003",
              "IPY_MODEL_dc523ea5287d482091ced0439a773404"
            ],
            "layout": "IPY_MODEL_680fc3a1e76a4b7a980b877c35b1fad4"
          }
        },
        "9dbe518d3ff146b18b4ad76aa1d3cea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53bb48c0c1c040f78952201729e9ce16",
            "placeholder": "",
            "style": "IPY_MODEL_30c97ef9e70542219966f139617911e0",
            "value": "2.18M/2.18M[00:00&lt;00:00,64.6MB/s]"
          }
        },
        "a0664d158e20430db1bb60cc2d7f185b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a08999fa606049eeb3f58a6aa53a07a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0eb9bfc9b684d478e9701c6124785bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a378d93f454544bb9df4c6add809fcd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a577405ea4be42ae88186491d7b91280": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1353f0ea70ed47949a8b261713b7495c",
            "max": 146413,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a378d93f454544bb9df4c6add809fcd0",
            "value": 146413
          }
        },
        "a932a5b438cd4b0fb413d280d50c67ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9ca8b9ac51c4d5c93ac8c320ef95435": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9d0a251d3bb4f60bc80d0100da51bea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac4264146375477ab1bc2cc51c3f3f0a",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a050c27907647d7957c08f4622b3239",
            "value": 7
          }
        },
        "ac4264146375477ab1bc2cc51c3f3f0a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3a0b6f84b1b4065a3a849afc67b4707": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5b290bdc453402899b0ff584d4e0102": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8dac3a2723f4b48b1e2a42fb80af21a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bac2b959dd48467999e4de0a35e40f46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_235010e5be824fc78c437798919b7aff",
            "placeholder": "",
            "style": "IPY_MODEL_5eb4b2df28984870baa386fe4851f2aa",
            "value": "5.87M/5.87M[00:00&lt;00:00,119MB/s]"
          }
        },
        "be724d16178040068ef23f6de6dbdd95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7150b1a4491a49ffb76a9c51788c1e11",
            "placeholder": "",
            "style": "IPY_MODEL_a0664d158e20430db1bb60cc2d7f185b",
            "value": "7/7[00:01&lt;00:00,3.15it/s]"
          }
        },
        "c0ef27fa4ecb491aa44deb9c3a0ea29b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c26be6e5f4eb4839b0c0da2d252b43ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2bf5b63b0504d65b448359e48335134": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c858ae4afc0c4e7292f951cf5894e288": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db49cdd3be8c46a4b18e04aae9faf9eb",
            "placeholder": "",
            "style": "IPY_MODEL_b3a0b6f84b1b4065a3a849afc67b4707",
            "value": "README.md:100%"
          }
        },
        "c923ee2a94fb47018262a160e8451ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ced77bb7976747e18b76530bcaa4d6c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf1fce484c0a421fa42931ed02de5efc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb33ca2d541d4dcc90918284090eccf3",
              "IPY_MODEL_d4f09c069fa441749c1973578c01dc2e",
              "IPY_MODEL_daf1403b677d45ada45972d2b571e12d"
            ],
            "layout": "IPY_MODEL_6d4813ee307c483b86aec12f93fa813b"
          }
        },
        "cf32f42df2594049ac647efa635cdfa8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d00f9b5d11644039b239e870f0db164f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2c79bbdbbeb4424a105c7599bead272": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4f09c069fa441749c1973578c01dc2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8851da4478154448a80b4f0fea0706d2",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93e1ff14a697408a9d906c9d9666d924",
            "value": 100
          }
        },
        "daf1403b677d45ada45972d2b571e12d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de27bf9e66c94fc9a1fe44bd4207bab6",
            "placeholder": "",
            "style": "IPY_MODEL_1f0048f5453b42ceb0691039fc294454",
            "value": "100/100[02:00&lt;00:00,1.21s/it]"
          }
        },
        "db49cdd3be8c46a4b18e04aae9faf9eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc523ea5287d482091ced0439a773404": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf32f42df2594049ac647efa635cdfa8",
            "placeholder": "",
            "style": "IPY_MODEL_09ea73a133e84659aa1bdb89f9e06be2",
            "value": "217k/217k[00:00&lt;00:00,5.18MB/s]"
          }
        },
        "de27bf9e66c94fc9a1fe44bd4207bab6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df4ddfdbafc94945a5234d81a62577c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18da201f07e44ba69ac5f234ed431d52",
              "IPY_MODEL_a577405ea4be42ae88186491d7b91280",
              "IPY_MODEL_88b4856bbd594e88a6bfe283d43e39fa"
            ],
            "layout": "IPY_MODEL_1f07c99bc3e24846b65d2060ffa1bf44"
          }
        },
        "e0c80050023f466bac0c8e9b371f0b5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e1463f4a7074b3ca56b435e9e29d4f3",
            "max": 1600,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2343eed89b2d4410ab729d5d3610bc6c",
            "value": 1600
          }
        },
        "e50248c836e54fa7b2ba108555b63afe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e540d93d806f4ef4917d8212ffb59f09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d1ca86022ea45bb8755e955fd66f95f",
            "placeholder": "",
            "style": "IPY_MODEL_a9ca8b9ac51c4d5c93ac8c320ef95435",
            "value": "variables.data-00000-of-00001:100%"
          }
        },
        "eb33ca2d541d4dcc90918284090eccf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66d17a3fc54b4cb986b2a0150223445c",
            "placeholder": "",
            "style": "IPY_MODEL_48e929dab75c410d87bfff1f7c7c1824",
            "value": "100%"
          }
        },
        "f029ea9cfb5b4330af25157968b0084d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f40c037a4388487a91600a9250c8d2b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f54b89f4680840688f0afc25bada35ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7d4002dc5474b248fc7b7177081d2e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7ffb1e648cc40d78b3685f451115841": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb0d852a0170492d9bb49f891bb05003": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b2c7c1e656c47b48501883d06cf3a40",
            "max": 216743,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8631ea8151d34fe1b478a7aa9665c2f5",
            "value": 216743
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
